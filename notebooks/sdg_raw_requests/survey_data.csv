Question	TI-ABS-KW	Id respondent	SDG	I don't know	Irrelevant	OK, relevant
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-10	SDG16	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-85	SDG16	null	null	1
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-17	SDG15	null	null	1
Q2028	An interdisciplinary approach to the study of extreme weather events: Large-scale atmospheric controls and insights from dynamical systems theory and statistical mechanics The workshop on 'Large-Scale Atmospheric Controls of Extreme Weather Events and Novel Predictability Pathways' gathered speakers with a wide range of backgrounds to foster such cross-disciplinary interactions. A specific focus was on identifying novel analysis techniques to describe large-scale atmospheric flows and their links to extreme weather events. Tim Woollings analyzed the eddy-driven jet stream's variability on daily to decadal time scales. He showed a complex interplay between these time scales, with decadal variations in jet speed modulating the shorter-term variability in the jet's latitudinal location. Lynn McMurdie focused in more detail on intense precipitation events associated with extratropical cyclones. Dynamical systems; Statistical mechanics; Storms; Analysis techniques; Atmospheric controls; Cross-disciplinary; Decadal timescale; Decadal variations; Extratropical cyclones; Extreme weather events; Intense precipitation; Weather information services  	L-10	SDG13	null	null	1
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-31	SDG7	null	null	1
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-10	SDG11	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-10	SDG1	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-10	SDG3	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-10	SDG4	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-10	SDG16	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-85	SDG12	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-93	SDG3	null	null	1
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-10	SDG8	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-80	SDG3	null	null	1
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-89	SDG12	null	null	1
Q181302	Influence of construction material uncertainties on residential building LCA reliability Life cycle assessment (LCA) is widely used to evaluate the environmental impacts of buildings, but due to uncertainties, the final results can be unreliable. To increase the reliability of LCA results, this study identifies the building materials that have the largest relative contribution to buildings' impacts and uncertainties. To do so, the impacts of 15 single-family houses and 15 multi-family building projects situated in France are evaluated. Only the uncertainties related to input parameters for building materials are considered (service life, characterization factors and quantity). The results obtained in this study show that LCA will still be able to distinguish significantly between two projects if their difference is higher than approximately 20%. Furthermore, the impacts of the buildings' exploitation phase do not show any correlations with the impacts related to the construction materials. The exploitation phase dominates the non-renewable energy consumption while waste impacts are most influenced by building materials. The contribution to global warming potential is shared between both phases. Finally, reinforced concrete was identified as the largest contributor to the environmental impact of both building types. In contrast, insulation materials and non-structural wood were the largest contributors to the uncertainties of the final results for single-family houses and multi-family buildings, respectively. 2016 Elsevier Ltd Building LCA; Relative contribution; Uncertainties Buildings; Characterization; Construction; Energy utilization; Environmental impact; Global warming; Houses; Life cycle; Reinforced concrete; Characterization factors; Global warming potential; Influence of construction; Insulation materials; Life Cycle Assessment (LCA); Relative contribution; Residential building; Uncertainties; Building materials  	L-10	SDG7	null	null	1
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-10	SDG2	null	null	1
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-10	SDG12	null	null	1
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-10	SDG9	null	null	1
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-80	SDG9	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-63	SDG11	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-79	SDG11	null	null	1
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-6	SDG7	null	null	1
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-15	SDG7	null	null	1
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-10	SDG2	null	null	1
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-71	SDG2	null	null	1
Q810	Waste Municipal Service and Informal Recycling Sector in Fast-Growing Asian Cities: Co-Existence, Opposition or Integration? Despite being generally poorly recognized by public authorities, informal recycling remains nevertheless a major component in the waste sector, which questions the legitimacy of the official waste arrangements. A look at the current transformation in Hanoi (Vietnam), Delhi (India) and Surabaya (Indonesia) allows us to understand the socio-technical aspects of infrastructural choices in the management of waste generated in fast-growing Asian cities. The three cases present similar traditional recycling practices yet contrasted (non-) regulation within their waste policies. From the co-existence of a municipal waste management service with a traditional informal recycling sector, to an opposition between both, there is also a possibility of making use of the existing local practices to achieve a more sustainable system. waste management; linear system; recycling; informal sector; Hanoi; Surabaya; Delhi COUNTRIES  	L-10	SDG11	null	null	1
Q810	Waste Municipal Service and Informal Recycling Sector in Fast-Growing Asian Cities: Co-Existence, Opposition or Integration? Despite being generally poorly recognized by public authorities, informal recycling remains nevertheless a major component in the waste sector, which questions the legitimacy of the official waste arrangements. A look at the current transformation in Hanoi (Vietnam), Delhi (India) and Surabaya (Indonesia) allows us to understand the socio-technical aspects of infrastructural choices in the management of waste generated in fast-growing Asian cities. The three cases present similar traditional recycling practices yet contrasted (non-) regulation within their waste policies. From the co-existence of a municipal waste management service with a traditional informal recycling sector, to an opposition between both, there is also a possibility of making use of the existing local practices to achieve a more sustainable system. waste management; linear system; recycling; informal sector; Hanoi; Surabaya; Delhi COUNTRIES  	L-72	SDG11	null	null	1
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-77	SDG7	null	null	1
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-89	SDG7	null	null	1
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-75	SDG9	null	null	1
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-85	SDG9	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-83	SDG7	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-85	SDG7	null	null	1
Q2312	Evaluation of contaminant retention in the soil of sustainable drainage systems: methodological reflections on the determination of sorption isotherms Runoff infiltration in Sustainable Drainage Systems enables the interception of a part of urban contaminant fluxes owing to several processes. The soil's ability to retain dissolved pollutants is generally assessed via sorption isotherms obtained from batch studies; however, the experimental points are not always in the same range as runoff concentrations. The present work (i) explores the consequences of modelling runoff–soil interactions from out-of-range equilibrium concentrations and (ii) proposes an improved method to ensure that experimental points fall within the desired range. Uncertainty analysis demonstrates that for a non-linear isotherm, using an extrapolated relationship may introduce significant biases in the ensuing estimations. Therefore, the proposed method consists of anticipating the equilibrium state of batch tests to accurately set the experimental conditions and reach appropriate concentrations. It is successfully applied to the determination of the sorption properties of copper and zinc onto three soils with different electrolyte solutions, as well as those of bisphenol A and three alkylphenols onto one soil. The contrasting affinities between the studied species and the soil materials could be related to their intrinsic properties and the soils' pedological parameters, as well as the presence of salt or dissolved organic ligands which partially inhibited metal sorption.  	L-10	SDG11	null	null	1
Q2312	Evaluation of contaminant retention in the soil of sustainable drainage systems: methodological reflections on the determination of sorption isotherms Runoff infiltration in Sustainable Drainage Systems enables the interception of a part of urban contaminant fluxes owing to several processes. The soil's ability to retain dissolved pollutants is generally assessed via sorption isotherms obtained from batch studies; however, the experimental points are not always in the same range as runoff concentrations. The present work (i) explores the consequences of modelling runoff–soil interactions from out-of-range equilibrium concentrations and (ii) proposes an improved method to ensure that experimental points fall within the desired range. Uncertainty analysis demonstrates that for a non-linear isotherm, using an extrapolated relationship may introduce significant biases in the ensuing estimations. Therefore, the proposed method consists of anticipating the equilibrium state of batch tests to accurately set the experimental conditions and reach appropriate concentrations. It is successfully applied to the determination of the sorption properties of copper and zinc onto three soils with different electrolyte solutions, as well as those of bisphenol A and three alkylphenols onto one soil. The contrasting affinities between the studied species and the soil materials could be related to their intrinsic properties and the soils' pedological parameters, as well as the presence of salt or dissolved organic ligands which partially inhibited metal sorption.  	L-96	SDG11	null	null	1
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-47	SDG13	null	null	1
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-52	SDG13	null	null	1
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-6	SDG7	null	null	1
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-33	SDG7	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-75	SDG15	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-83	SDG15	null	null	1
Q04889	Intermittent large amplitude internal waves observed in Port Susan, Puget Sound A previously unreported internal tidal bore, which evolves into solitary internal wave packets, was observed in Port Susan, Puget Sound, and the timing, speed, and amplitude of the waves were measured by CTD and visual observation. Acoustic Doppler current profiler (ADCP) measurements were attempted, but unsuccessful. The waves appear to be generated with the ebb flow along the tidal flats of the Stillaguamish River, and the speed and width of the resulting waves can be predicted from second-order KdV theory. Their eventual dissipation may contribute significantly to surface mixing locally, particularly in comparison with the local dissipation due to the tides. Visually the waves appear in fair weather as a strong foam front, which is less visible the farther they propagate. 2017 Elsevier Ltd Coastal waters; Internal waves; Korteweg-de Vries equation; Mixing processes; Tidal effects Acoustic Doppler Current Profiler; coastal water; comparative study; equation; internal wave; intertidal environment; mixing; reaction kinetics; tidal flat; Puget Sound; Stillaguamish River; United States; Washington [United States]  	L-10	SDG14	null	null	1
Q04889	Intermittent large amplitude internal waves observed in Port Susan, Puget Sound A previously unreported internal tidal bore, which evolves into solitary internal wave packets, was observed in Port Susan, Puget Sound, and the timing, speed, and amplitude of the waves were measured by CTD and visual observation. Acoustic Doppler current profiler (ADCP) measurements were attempted, but unsuccessful. The waves appear to be generated with the ebb flow along the tidal flats of the Stillaguamish River, and the speed and width of the resulting waves can be predicted from second-order KdV theory. Their eventual dissipation may contribute significantly to surface mixing locally, particularly in comparison with the local dissipation due to the tides. Visually the waves appear in fair weather as a strong foam front, which is less visible the farther they propagate. 2017 Elsevier Ltd Coastal waters; Internal waves; Korteweg-de Vries equation; Mixing processes; Tidal effects Acoustic Doppler Current Profiler; coastal water; comparative study; equation; internal wave; intertidal environment; mixing; reaction kinetics; tidal flat; Puget Sound; Stillaguamish River; United States; Washington [United States]  	L-40	SDG14	null	null	1
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-46	SDG14	null	null	1
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-86	SDG14	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-10	SDG8	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-96	SDG8	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-42	SDG14	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-75	SDG14	null	null	1
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-77	SDG7	null	null	1
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-89	SDG7	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-10	SDG7	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-72	SDG7	null	null	1
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-77	SDG13	null	null	1
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-89	SDG13	null	null	1
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-78	SDG3	null	null	1
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-86	SDG3	null	null	1
Q142927	A Theory of Political Entrenchment Can an incumbent political party increase its chances at re-election by implementing inefficient policies that harm its constituency? This paper studies the possibility of such a phenomenon, which we label political entrenchment. We use a two-party dynamic model of redistribution with probabilistic voting. Political entrenchment by the Left occurs only if incumbency rents are sufficiently high. Low-skill citizens may vote for this party even though they rationally expect the adoption of these policies. We discuss: the possibility of entrenchment by the Right; the scope for commitment to avoid entrenchment policies; and the effect of state capacity, income inequality and party popularity on the likelihood of entrenchment. We illustrate our theory with a number of historical examples. 2014 Royal Economic Society election; modeling; party politics; political theory; voting behavior  	L-10	SDG10	null	null	1
Q142927	A Theory of Political Entrenchment Can an incumbent political party increase its chances at re-election by implementing inefficient policies that harm its constituency? This paper studies the possibility of such a phenomenon, which we label political entrenchment. We use a two-party dynamic model of redistribution with probabilistic voting. Political entrenchment by the Left occurs only if incumbency rents are sufficiently high. Low-skill citizens may vote for this party even though they rationally expect the adoption of these policies. We discuss: the possibility of entrenchment by the Right; the scope for commitment to avoid entrenchment policies; and the effect of state capacity, income inequality and party popularity on the likelihood of entrenchment. We illustrate our theory with a number of historical examples. 2014 Royal Economic Society election; modeling; party politics; political theory; voting behavior  	L-65	SDG10	null	null	1
Q181302	Influence of construction material uncertainties on residential building LCA reliability Life cycle assessment (LCA) is widely used to evaluate the environmental impacts of buildings, but due to uncertainties, the final results can be unreliable. To increase the reliability of LCA results, this study identifies the building materials that have the largest relative contribution to buildings' impacts and uncertainties. To do so, the impacts of 15 single-family houses and 15 multi-family building projects situated in France are evaluated. Only the uncertainties related to input parameters for building materials are considered (service life, characterization factors and quantity). The results obtained in this study show that LCA will still be able to distinguish significantly between two projects if their difference is higher than approximately 20%. Furthermore, the impacts of the buildings' exploitation phase do not show any correlations with the impacts related to the construction materials. The exploitation phase dominates the non-renewable energy consumption while waste impacts are most influenced by building materials. The contribution to global warming potential is shared between both phases. Finally, reinforced concrete was identified as the largest contributor to the environmental impact of both building types. In contrast, insulation materials and non-structural wood were the largest contributors to the uncertainties of the final results for single-family houses and multi-family buildings, respectively. 2016 Elsevier Ltd Building LCA; Relative contribution; Uncertainties Buildings; Characterization; Construction; Energy utilization; Environmental impact; Global warming; Houses; Life cycle; Reinforced concrete; Characterization factors; Global warming potential; Influence of construction; Insulation materials; Life Cycle Assessment (LCA); Relative contribution; Residential building; Uncertainties; Building materials  	L-10	SDG12	null	null	1
Q181302	Influence of construction material uncertainties on residential building LCA reliability Life cycle assessment (LCA) is widely used to evaluate the environmental impacts of buildings, but due to uncertainties, the final results can be unreliable. To increase the reliability of LCA results, this study identifies the building materials that have the largest relative contribution to buildings' impacts and uncertainties. To do so, the impacts of 15 single-family houses and 15 multi-family building projects situated in France are evaluated. Only the uncertainties related to input parameters for building materials are considered (service life, characterization factors and quantity). The results obtained in this study show that LCA will still be able to distinguish significantly between two projects if their difference is higher than approximately 20%. Furthermore, the impacts of the buildings' exploitation phase do not show any correlations with the impacts related to the construction materials. The exploitation phase dominates the non-renewable energy consumption while waste impacts are most influenced by building materials. The contribution to global warming potential is shared between both phases. Finally, reinforced concrete was identified as the largest contributor to the environmental impact of both building types. In contrast, insulation materials and non-structural wood were the largest contributors to the uncertainties of the final results for single-family houses and multi-family buildings, respectively. 2016 Elsevier Ltd Building LCA; Relative contribution; Uncertainties Buildings; Characterization; Construction; Energy utilization; Environmental impact; Global warming; Houses; Life cycle; Reinforced concrete; Characterization factors; Global warming potential; Influence of construction; Insulation materials; Life Cycle Assessment (LCA); Relative contribution; Residential building; Uncertainties; Building materials  	L-10	SDG13	null	null	1
Q181302	Influence of construction material uncertainties on residential building LCA reliability Life cycle assessment (LCA) is widely used to evaluate the environmental impacts of buildings, but due to uncertainties, the final results can be unreliable. To increase the reliability of LCA results, this study identifies the building materials that have the largest relative contribution to buildings' impacts and uncertainties. To do so, the impacts of 15 single-family houses and 15 multi-family building projects situated in France are evaluated. Only the uncertainties related to input parameters for building materials are considered (service life, characterization factors and quantity). The results obtained in this study show that LCA will still be able to distinguish significantly between two projects if their difference is higher than approximately 20%. Furthermore, the impacts of the buildings' exploitation phase do not show any correlations with the impacts related to the construction materials. The exploitation phase dominates the non-renewable energy consumption while waste impacts are most influenced by building materials. The contribution to global warming potential is shared between both phases. Finally, reinforced concrete was identified as the largest contributor to the environmental impact of both building types. In contrast, insulation materials and non-structural wood were the largest contributors to the uncertainties of the final results for single-family houses and multi-family buildings, respectively. 2016 Elsevier Ltd Building LCA; Relative contribution; Uncertainties Buildings; Characterization; Construction; Energy utilization; Environmental impact; Global warming; Houses; Life cycle; Reinforced concrete; Characterization factors; Global warming potential; Influence of construction; Insulation materials; Life Cycle Assessment (LCA); Relative contribution; Residential building; Uncertainties; Building materials  	L-72	SDG12	null	null	1
Q181302	Influence of construction material uncertainties on residential building LCA reliability Life cycle assessment (LCA) is widely used to evaluate the environmental impacts of buildings, but due to uncertainties, the final results can be unreliable. To increase the reliability of LCA results, this study identifies the building materials that have the largest relative contribution to buildings' impacts and uncertainties. To do so, the impacts of 15 single-family houses and 15 multi-family building projects situated in France are evaluated. Only the uncertainties related to input parameters for building materials are considered (service life, characterization factors and quantity). The results obtained in this study show that LCA will still be able to distinguish significantly between two projects if their difference is higher than approximately 20%. Furthermore, the impacts of the buildings' exploitation phase do not show any correlations with the impacts related to the construction materials. The exploitation phase dominates the non-renewable energy consumption while waste impacts are most influenced by building materials. The contribution to global warming potential is shared between both phases. Finally, reinforced concrete was identified as the largest contributor to the environmental impact of both building types. In contrast, insulation materials and non-structural wood were the largest contributors to the uncertainties of the final results for single-family houses and multi-family buildings, respectively. 2016 Elsevier Ltd Building LCA; Relative contribution; Uncertainties Buildings; Characterization; Construction; Energy utilization; Environmental impact; Global warming; Houses; Life cycle; Reinforced concrete; Characterization factors; Global warming potential; Influence of construction; Insulation materials; Life Cycle Assessment (LCA); Relative contribution; Residential building; Uncertainties; Building materials  	L-72	SDG13	null	null	1
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-10	SDG6	null	null	1
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-10	SDG11	null	null	1
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-72	SDG6	null	null	1
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-72	SDG11	null	null	1
Q213019	Income concentration in British India, 1885–1946 We use a novel income tax data set to present evidence on the evolution of income concentration in the last 60 years of colonial rule in India. These data allow us to study the evolution of income concentration at the country level as well as the location of top income earners across provinces. We identify three key facts: (1) the evolution of income concentration in British India was nonlinear, following a U-shape, (2) the majority of top income earners were non-Europeans, and (3) the geographical location of top income earners changed over time with the province of Bombay gaining in importance in the early XXth century. We provide an interpretation of these results in the light of the economic and political changes in British India over the period. 2017 Elsevier B.V. Colonization; India; Inequality; Top incomes colonialism; colonization; data set; economic history; economic reform; equity; income distribution; political change; tax system; India; Maharashtra; Mumbai  	L-10	SDG10	null	null	1
Q213019	Income concentration in British India, 1885–1946 We use a novel income tax data set to present evidence on the evolution of income concentration in the last 60 years of colonial rule in India. These data allow us to study the evolution of income concentration at the country level as well as the location of top income earners across provinces. We identify three key facts: (1) the evolution of income concentration in British India was nonlinear, following a U-shape, (2) the majority of top income earners were non-Europeans, and (3) the geographical location of top income earners changed over time with the province of Bombay gaining in importance in the early XXth century. We provide an interpretation of these results in the light of the economic and political changes in British India over the period. 2017 Elsevier B.V. Colonization; India; Inequality; Top incomes colonialism; colonization; data set; economic history; economic reform; equity; income distribution; political change; tax system; India; Maharashtra; Mumbai  	L-72	SDG10	null	null	1
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-25	SDG16	null	null	1
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-77	SDG16	null	null	1
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-10	SDG11	null	null	1
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-72	SDG11	null	null	1
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-80	SDG11	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-46	SDG2	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-47	SDG12	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-63	SDG2	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-63	SDG12	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-79	SDG2	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-79	SDG12	null	null	1
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-15	SDG11	null	null	1
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-47	SDG11	null	null	1
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-52	SDG11	null	null	1
Q2232	National survey of telemedicine education and training in medical schools in France Introduction: Telemedicine is a remote medical practice using information communication technology (ICT), and has been increasing in France since 2009. With all new forms of medical practice, education and training (ET) is required for quality and safety. To date, implementation of telemedicine ET has not been assessed in France. The objective of this study was to describe the implementation of telemedicine ET and evaluate the knowledge, attitudes and practices (KAP) of deans and associate deans from all medical schools in France. Methods: A cross-sectional non-mandatory, descriptive online survey with a self-administered questionnaire was performed from 15 November to 6 December, 2017. Respondents were accessed through the ‘Conférence des doyens des Facultés de médecine’. Results: There were 48 respondents with a 47.4% response rate among deans. Telemedicine ET was limited in France; 10.4% in 1st year medicine (PACES); 4% in the final 3 years of medical school (D.F.A.S.M.) and 18.8% in medical residency. Emergency medicine, dermatology, radiology, neurology and geriatrics were specialties with implemented telemedicine training during residency. Of all respondents, 90% expressed a need to increase telemedicine ET, among which 75% accepted external support. A highly positive attitude towards telemedicine practice was reflected by 60.4% of respondents, and 56.2% practiced telemedicine at least once. Discussion: This study was the first to assess national telemedicine ET implementation in France. Telemedicine was integrated into initial medical education; however, telemedicine ET remains limited despite the positive attitudes of deans and associate deans. Further research would need to be conducted on telemedicine ET implementation and KAP of medical students and residents. The Author(s) 2019. curriculum; medical education; medical school; residency training; Telemedicine adult; article; clinical article; curriculum; dermatology; emergency medicine; female; France; geriatrics; human; human experiment; male; medical school; medical student; neurology; questionnaire; radiology; residency education; telemedicine; attitude  	L-47	SDG3	null	null	1
Q2232	National survey of telemedicine education and training in medical schools in France Introduction: Telemedicine is a remote medical practice using information communication technology (ICT), and has been increasing in France since 2009. With all new forms of medical practice, education and training (ET) is required for quality and safety. To date, implementation of telemedicine ET has not been assessed in France. The objective of this study was to describe the implementation of telemedicine ET and evaluate the knowledge, attitudes and practices (KAP) of deans and associate deans from all medical schools in France. Methods: A cross-sectional non-mandatory, descriptive online survey with a self-administered questionnaire was performed from 15 November to 6 December, 2017. Respondents were accessed through the ‘Conférence des doyens des Facultés de médecine’. Results: There were 48 respondents with a 47.4% response rate among deans. Telemedicine ET was limited in France; 10.4% in 1st year medicine (PACES); 4% in the final 3 years of medical school (D.F.A.S.M.) and 18.8% in medical residency. Emergency medicine, dermatology, radiology, neurology and geriatrics were specialties with implemented telemedicine training during residency. Of all respondents, 90% expressed a need to increase telemedicine ET, among which 75% accepted external support. A highly positive attitude towards telemedicine practice was reflected by 60.4% of respondents, and 56.2% practiced telemedicine at least once. Discussion: This study was the first to assess national telemedicine ET implementation in France. Telemedicine was integrated into initial medical education; however, telemedicine ET remains limited despite the positive attitudes of deans and associate deans. Further research would need to be conducted on telemedicine ET implementation and KAP of medical students and residents. The Author(s) 2019. curriculum; medical education; medical school; residency training; Telemedicine adult; article; clinical article; curriculum; dermatology; emergency medicine; female; France; geriatrics; human; human experiment; male; medical school; medical student; neurology; questionnaire; radiology; residency education; telemedicine; attitude  	L-78	SDG3	null	null	1
Q2232	National survey of telemedicine education and training in medical schools in France Introduction: Telemedicine is a remote medical practice using information communication technology (ICT), and has been increasing in France since 2009. With all new forms of medical practice, education and training (ET) is required for quality and safety. To date, implementation of telemedicine ET has not been assessed in France. The objective of this study was to describe the implementation of telemedicine ET and evaluate the knowledge, attitudes and practices (KAP) of deans and associate deans from all medical schools in France. Methods: A cross-sectional non-mandatory, descriptive online survey with a self-administered questionnaire was performed from 15 November to 6 December, 2017. Respondents were accessed through the ‘Conférence des doyens des Facultés de médecine’. Results: There were 48 respondents with a 47.4% response rate among deans. Telemedicine ET was limited in France; 10.4% in 1st year medicine (PACES); 4% in the final 3 years of medical school (D.F.A.S.M.) and 18.8% in medical residency. Emergency medicine, dermatology, radiology, neurology and geriatrics were specialties with implemented telemedicine training during residency. Of all respondents, 90% expressed a need to increase telemedicine ET, among which 75% accepted external support. A highly positive attitude towards telemedicine practice was reflected by 60.4% of respondents, and 56.2% practiced telemedicine at least once. Discussion: This study was the first to assess national telemedicine ET implementation in France. Telemedicine was integrated into initial medical education; however, telemedicine ET remains limited despite the positive attitudes of deans and associate deans. Further research would need to be conducted on telemedicine ET implementation and KAP of medical students and residents. The Author(s) 2019. curriculum; medical education; medical school; residency training; Telemedicine adult; article; clinical article; curriculum; dermatology; emergency medicine; female; France; geriatrics; human; human experiment; male; medical school; medical student; neurology; questionnaire; radiology; residency education; telemedicine; attitude  	L-86	SDG3	null	null	1
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-10	SDG15	null	null	1
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-72	SDG15	null	null	1
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-96	SDG15	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-50	SDG8	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-77	SDG8	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-89	SDG8	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-10	SDG13	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-72	SDG13	null	null	1
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-96	SDG13	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-10	SDG10	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-65	SDG10	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-80	SDG10	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-10	SDG8	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-65	SDG8	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-96	SDG8	null	null	1
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-37	SDG1	null	null	1
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-52	SDG1	null	null	1
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-63	SDG1	null	null	1
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-47	SDG13	null	null	1
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-78	SDG13	null	null	1
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-86	SDG13	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-15	SDG14	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-78	SDG14	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-86	SDG14	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-23	SDG13	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-60	SDG13	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-85	SDG13	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-93	SDG13	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-10	SDG1	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-10	SDG16	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-13	SDG1	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-13	SDG16	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-40	SDG16	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-48	SDG16	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-65	SDG1	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-72	SDG1	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-42	SDG10	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-60	SDG10	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-60	SDG16	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-75	SDG10	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-75	SDG16	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-85	SDG10	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-85	SDG16	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-93	SDG16	null	null	1
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-46	SDG11	null	null	1
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-47	SDG11	null	null	1
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-52	SDG11	null	null	1
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-86	SDG11	null	null	1
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-10	SDG15	null	null	1
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-71	SDG15	null	null	1
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-72	SDG15	null	null	1
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-96	SDG15	null	null	1
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-60	SDG11	null	null	1
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-75	SDG11	null	null	1
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-85	SDG11	null	null	1
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-90	SDG11	null	null	1
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-46	SDG6	null	null	1
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-52	SDG6	null	null	1
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-74	SDG6	null	null	1
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-78	SDG6	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-46	SDG16	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-74	SDG16	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-78	SDG16	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-86	SDG16	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-10	SDG3	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-65	SDG3	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-71	SDG3	null	null	1
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-80	SDG3	null	null	1
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-50	SDG1	null	null	1
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-77	SDG1	null	null	1
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-89	SDG1	null	null	1
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-92	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-25	SDG9	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-32	SDG9	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-89	SDG9	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-92	SDG9	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-10	SDG1	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-65	SDG1	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-72	SDG1	null	null	1
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-96	SDG1	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-15	SDG13	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-47	SDG13	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-78	SDG13	null	null	1
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-86	SDG13	null	null	1
Q191558	Non-target strategies by HRMS to evaluate fluidized micro-grain activated carbon as a tertiary treatment of wastewater Among the release solutions for reducing the discharge of organic and persistent contaminants in the aquatic environment, the use of a tertiary treatment in addition to existing conventional wastewater treatment processes is considered. The use of micro-grain activated carbon in a fluidized bed is a promising technique investigated in this study. The effluents from a large-scale pilot system were analyzed by liquid chromatography coupled with high-resolution mass spectrometry (QToF). Several strategies were deployed, namely molecular fingerprint comparison, suspected and non-target analyses, identification of refractory compounds to treatment, and finally, quantification of identified compounds. The evaluation of the molecular fingerprints provided evidence of the overall effect of the tertiary treatment on the treated wastewater quality. The suspected approach highlighted the presence of 83 pharmaceuticals and pesticides as well as transformation products in the effluents. The non-target approaches also highlighted compounds refractory to tertiary treatment, such as illicit drugs or some pharmaceuticals. The identification and quantification of identified compounds underscored the suitability of micro-grain activated carbon in eliminating many classes of pharmaceuticals with various physicochemical properties, such as anti-hypertensive, analgesic, anti-viral, antidepressant and even various pesticides. 2018 Elsevier Ltd High-resolution mass spectrometry; Micropollutants; Non target; Refractory compounds; Tertiary treatment; µGAC Activated carbon; Drug products; Effluents; Fluidization; Fluidized beds; Liquid chromatography; Mass spectrometry; Pesticides; Quality control; Refractory materials; Wastewater treatment; High resolution mass spectrometry; Micropollutants; Molecular fingerprint; Physicochemical property; Refractory compounds; Tertiary treatment; Transformation products; Wastewater treatment process; Activated carbon treatment; activated carbon; analgesic agent; antidepressant agent; antihypertensive agent; antivirus agent; illicit drug; pesticide; charcoal; drug; pesticide; activated carbon; chemical pollutant; drug; effluent; liquid chromatography; mass spectrometry; pesticide; wastewater; wastewater treatment; aquatic environment; Article; effluent; fluidized bed; liquid chromatography; mass spectrometry; waste water management; analysis; chemistry; isolation and purification; mass spectrometry; procedures; waste water; water management; water pollutant; Analgesics; Antidepressive Agents; Antihypertensive Agents; Antiviral Agents; Charcoal; Mass Spectrometry; Pesticides; Pharmaceutical Preparations; Waste Water; Water Pollutants, Chemical; Water Purification  	L-10	SDG6	null	null	1
Q191558	Non-target strategies by HRMS to evaluate fluidized micro-grain activated carbon as a tertiary treatment of wastewater Among the release solutions for reducing the discharge of organic and persistent contaminants in the aquatic environment, the use of a tertiary treatment in addition to existing conventional wastewater treatment processes is considered. The use of micro-grain activated carbon in a fluidized bed is a promising technique investigated in this study. The effluents from a large-scale pilot system were analyzed by liquid chromatography coupled with high-resolution mass spectrometry (QToF). Several strategies were deployed, namely molecular fingerprint comparison, suspected and non-target analyses, identification of refractory compounds to treatment, and finally, quantification of identified compounds. The evaluation of the molecular fingerprints provided evidence of the overall effect of the tertiary treatment on the treated wastewater quality. The suspected approach highlighted the presence of 83 pharmaceuticals and pesticides as well as transformation products in the effluents. The non-target approaches also highlighted compounds refractory to tertiary treatment, such as illicit drugs or some pharmaceuticals. The identification and quantification of identified compounds underscored the suitability of micro-grain activated carbon in eliminating many classes of pharmaceuticals with various physicochemical properties, such as anti-hypertensive, analgesic, anti-viral, antidepressant and even various pesticides. 2018 Elsevier Ltd High-resolution mass spectrometry; Micropollutants; Non target; Refractory compounds; Tertiary treatment; µGAC Activated carbon; Drug products; Effluents; Fluidization; Fluidized beds; Liquid chromatography; Mass spectrometry; Pesticides; Quality control; Refractory materials; Wastewater treatment; High resolution mass spectrometry; Micropollutants; Molecular fingerprint; Physicochemical property; Refractory compounds; Tertiary treatment; Transformation products; Wastewater treatment process; Activated carbon treatment; activated carbon; analgesic agent; antidepressant agent; antihypertensive agent; antivirus agent; illicit drug; pesticide; charcoal; drug; pesticide; activated carbon; chemical pollutant; drug; effluent; liquid chromatography; mass spectrometry; pesticide; wastewater; wastewater treatment; aquatic environment; Article; effluent; fluidized bed; liquid chromatography; mass spectrometry; waste water management; analysis; chemistry; isolation and purification; mass spectrometry; procedures; waste water; water management; water pollutant; Analgesics; Antidepressive Agents; Antihypertensive Agents; Antiviral Agents; Charcoal; Mass Spectrometry; Pesticides; Pharmaceutical Preparations; Waste Water; Water Pollutants, Chemical; Water Purification  	L-65	SDG6	null	null	1
Q191558	Non-target strategies by HRMS to evaluate fluidized micro-grain activated carbon as a tertiary treatment of wastewater Among the release solutions for reducing the discharge of organic and persistent contaminants in the aquatic environment, the use of a tertiary treatment in addition to existing conventional wastewater treatment processes is considered. The use of micro-grain activated carbon in a fluidized bed is a promising technique investigated in this study. The effluents from a large-scale pilot system were analyzed by liquid chromatography coupled with high-resolution mass spectrometry (QToF). Several strategies were deployed, namely molecular fingerprint comparison, suspected and non-target analyses, identification of refractory compounds to treatment, and finally, quantification of identified compounds. The evaluation of the molecular fingerprints provided evidence of the overall effect of the tertiary treatment on the treated wastewater quality. The suspected approach highlighted the presence of 83 pharmaceuticals and pesticides as well as transformation products in the effluents. The non-target approaches also highlighted compounds refractory to tertiary treatment, such as illicit drugs or some pharmaceuticals. The identification and quantification of identified compounds underscored the suitability of micro-grain activated carbon in eliminating many classes of pharmaceuticals with various physicochemical properties, such as anti-hypertensive, analgesic, anti-viral, antidepressant and even various pesticides. 2018 Elsevier Ltd High-resolution mass spectrometry; Micropollutants; Non target; Refractory compounds; Tertiary treatment; µGAC Activated carbon; Drug products; Effluents; Fluidization; Fluidized beds; Liquid chromatography; Mass spectrometry; Pesticides; Quality control; Refractory materials; Wastewater treatment; High resolution mass spectrometry; Micropollutants; Molecular fingerprint; Physicochemical property; Refractory compounds; Tertiary treatment; Transformation products; Wastewater treatment process; Activated carbon treatment; activated carbon; analgesic agent; antidepressant agent; antihypertensive agent; antivirus agent; illicit drug; pesticide; charcoal; drug; pesticide; activated carbon; chemical pollutant; drug; effluent; liquid chromatography; mass spectrometry; pesticide; wastewater; wastewater treatment; aquatic environment; Article; effluent; fluidized bed; liquid chromatography; mass spectrometry; waste water management; analysis; chemistry; isolation and purification; mass spectrometry; procedures; waste water; water management; water pollutant; Analgesics; Antidepressive Agents; Antihypertensive Agents; Antiviral Agents; Charcoal; Mass Spectrometry; Pesticides; Pharmaceutical Preparations; Waste Water; Water Pollutants, Chemical; Water Purification  	L-72	SDG6	null	null	1
Q191558	Non-target strategies by HRMS to evaluate fluidized micro-grain activated carbon as a tertiary treatment of wastewater Among the release solutions for reducing the discharge of organic and persistent contaminants in the aquatic environment, the use of a tertiary treatment in addition to existing conventional wastewater treatment processes is considered. The use of micro-grain activated carbon in a fluidized bed is a promising technique investigated in this study. The effluents from a large-scale pilot system were analyzed by liquid chromatography coupled with high-resolution mass spectrometry (QToF). Several strategies were deployed, namely molecular fingerprint comparison, suspected and non-target analyses, identification of refractory compounds to treatment, and finally, quantification of identified compounds. The evaluation of the molecular fingerprints provided evidence of the overall effect of the tertiary treatment on the treated wastewater quality. The suspected approach highlighted the presence of 83 pharmaceuticals and pesticides as well as transformation products in the effluents. The non-target approaches also highlighted compounds refractory to tertiary treatment, such as illicit drugs or some pharmaceuticals. The identification and quantification of identified compounds underscored the suitability of micro-grain activated carbon in eliminating many classes of pharmaceuticals with various physicochemical properties, such as anti-hypertensive, analgesic, anti-viral, antidepressant and even various pesticides. 2018 Elsevier Ltd High-resolution mass spectrometry; Micropollutants; Non target; Refractory compounds; Tertiary treatment; µGAC Activated carbon; Drug products; Effluents; Fluidization; Fluidized beds; Liquid chromatography; Mass spectrometry; Pesticides; Quality control; Refractory materials; Wastewater treatment; High resolution mass spectrometry; Micropollutants; Molecular fingerprint; Physicochemical property; Refractory compounds; Tertiary treatment; Transformation products; Wastewater treatment process; Activated carbon treatment; activated carbon; analgesic agent; antidepressant agent; antihypertensive agent; antivirus agent; illicit drug; pesticide; charcoal; drug; pesticide; activated carbon; chemical pollutant; drug; effluent; liquid chromatography; mass spectrometry; pesticide; wastewater; wastewater treatment; aquatic environment; Article; effluent; fluidized bed; liquid chromatography; mass spectrometry; waste water management; analysis; chemistry; isolation and purification; mass spectrometry; procedures; waste water; water management; water pollutant; Analgesics; Antidepressive Agents; Antihypertensive Agents; Antiviral Agents; Charcoal; Mass Spectrometry; Pesticides; Pharmaceutical Preparations; Waste Water; Water Pollutants, Chemical; Water Purification  	L-96	SDG6	null	null	1
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-25	SDG13	null	null	1
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-77	SDG13	null	null	1
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-87	SDG13	null	null	1
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-89	SDG13	null	null	1
Q01hal01679709	Shifting Diets: Toward a Sustainable Food Future A global convergence toward Western-style diets that are high in calories, protein, and animal-based foods poses challenges for food security and sustainability. To quantify the benefits of shifting these consumers to more sustainable diets, several possible diet shifts are modeled. A framework is proposed to tackle the crucial question of how to shift people’s diets through the retail and food services sector.  	L-10	SDG2	null	null	1
Q01hal01679709	Shifting Diets: Toward a Sustainable Food Future A global convergence toward Western-style diets that are high in calories, protein, and animal-based foods poses challenges for food security and sustainability. To quantify the benefits of shifting these consumers to more sustainable diets, several possible diet shifts are modeled. A framework is proposed to tackle the crucial question of how to shift people’s diets through the retail and food services sector.  	L-13	SDG2	null	null	1
Q01hal01679709	Shifting Diets: Toward a Sustainable Food Future A global convergence toward Western-style diets that are high in calories, protein, and animal-based foods poses challenges for food security and sustainability. To quantify the benefits of shifting these consumers to more sustainable diets, several possible diet shifts are modeled. A framework is proposed to tackle the crucial question of how to shift people’s diets through the retail and food services sector.  	L-65	SDG2	null	null	1
Q01hal01679709	Shifting Diets: Toward a Sustainable Food Future A global convergence toward Western-style diets that are high in calories, protein, and animal-based foods poses challenges for food security and sustainability. To quantify the benefits of shifting these consumers to more sustainable diets, several possible diet shifts are modeled. A framework is proposed to tackle the crucial question of how to shift people’s diets through the retail and food services sector.  	L-72	SDG2	null	null	1
Q01hal01679709	Shifting Diets: Toward a Sustainable Food Future A global convergence toward Western-style diets that are high in calories, protein, and animal-based foods poses challenges for food security and sustainability. To quantify the benefits of shifting these consumers to more sustainable diets, several possible diet shifts are modeled. A framework is proposed to tackle the crucial question of how to shift people’s diets through the retail and food services sector.  	L-96	SDG2	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-15	SDG1	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-52	SDG1	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-74	SDG1	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-78	SDG1	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-86	SDG1	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-10	SDG5	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-13	SDG5	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-40	SDG5	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-65	SDG5	null	null	1
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-72	SDG5	null	null	1
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-18	SDG11	null	null	1
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-24	SDG11	null	null	1
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-77	SDG11	null	null	1
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-87	SDG11	null	null	1
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-89	SDG11	null	null	1
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-18	SDG15	null	null	1
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-25	SDG15	null	null	1
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-77	SDG15	null	null	1
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-87	SDG15	null	null	1
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-89	SDG15	null	null	1
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-55	SDG6	null	null	1
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-70	SDG6	null	null	1
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-83	SDG6	null	null	1
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-88	SDG6	null	null	1
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-90	SDG6	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-46	SDG8	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-46	SDG10	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-63	SDG8	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-63	SDG10	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-74	SDG8	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-74	SDG10	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-78	SDG8	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-78	SDG10	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-86	SDG8	null	null	1
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-86	SDG10	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-32	SDG1	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-50	SDG1	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-64	SDG1	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-77	SDG1	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-89	SDG1	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-10	SDG13	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-65	SDG13	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-72	SDG13	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-80	SDG13	null	null	1
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-96	SDG13	null	null	1
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-18	SDG2	null	null	1
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-25	SDG2	null	null	1
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-64	SDG2	null	null	1
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-77	SDG2	null	null	1
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-89	SDG2	null	null	1
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-11	SDG2	null	null	1
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-47	SDG2	null	null	1
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-74	SDG2	null	null	1
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-78	SDG2	null	null	1
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-86	SDG2	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-46	SDG7	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-47	SDG7	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-63	SDG7	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-78	SDG7	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-79	SDG7	null	null	1
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-86	SDG7	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-18	SDG8	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-24	SDG8	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-25	SDG8	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-77	SDG8	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-89	SDG8	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-92	SDG8	null	null	1
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-18	SDG8	null	null	1
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-54	SDG8	null	null	1
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-77	SDG8	null	null	1
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-87	SDG8	null	null	1
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-89	SDG8	null	null	1
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-92	SDG8	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-18	SDG11	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-24	SDG11	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-25	SDG11	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-54	SDG11	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-77	SDG11	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-89	SDG11	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-30	SDG14	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-38	SDG14	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-60	SDG14	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-75	SDG14	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-83	SDG14	null	null	1
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-90	SDG14	null	null	1
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-6	SDG3	null	null	1
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-20	SDG3	null	null	1
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-32	SDG3	null	null	1
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-38	SDG3	null	null	1
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-41	SDG3	null	null	1
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-42	SDG3	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-30	SDG11	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-60	SDG11	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-62	SDG11	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-69	SDG11	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-83	SDG11	null	null	1
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-85	SDG11	null	null	1
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-45	SDG3	null	null	1
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-47	SDG3	null	null	1
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-63	SDG3	null	null	1
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-74	SDG3	null	null	1
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-78	SDG3	null	null	1
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-86	SDG3	null	null	1
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-37	SDG10	null	null	1
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-46	SDG10	null	null	1
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-47	SDG10	null	null	1
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-74	SDG10	null	null	1
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-78	SDG10	null	null	1
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-86	SDG10	null	null	1
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-30	SDG10	null	null	1
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-38	SDG10	null	null	1
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-42	SDG10	null	null	1
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-62	SDG10	null	null	1
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-66	SDG10	null	null	1
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-83	SDG10	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-15	SDG3	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-20	SDG3	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-47	SDG3	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-52	SDG3	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-74	SDG3	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-78	SDG3	null	null	1
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-86	SDG3	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-23	SDG15	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-38	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-42	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-60	SDG15	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-62	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-62	SDG15	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-66	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-69	SDG15	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-75	SDG15	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-85	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-85	SDG15	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-90	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-93	SDG11	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-93	SDG15	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-24	SDG8	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-32	SDG8	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-50	SDG8	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-77	SDG8	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-87	SDG8	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-89	SDG8	null	null	1
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-92	SDG8	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-23	SDG11	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-42	SDG11	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-60	SDG11	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-75	SDG11	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-85	SDG11	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-88	SDG11	null	null	1
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-90	SDG11	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-6	SDG8	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-15	SDG8	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-20	SDG8	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-22	SDG8	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-29	SDG8	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-37	SDG8	null	null	1
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-38	SDG8	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-24	SDG11	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-25	SDG11	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-32	SDG11	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-50	SDG11	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-64	SDG11	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-77	SDG11	null	null	1
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-89	SDG11	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-23	SDG12	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-42	SDG12	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-60	SDG12	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-75	SDG12	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-85	SDG12	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-88	SDG12	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-93	SDG12	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-24	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-25	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-50	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-77	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-87	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-89	SDG1	null	null	1
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-92	SDG1	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-42	SDG2	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-60	SDG2	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-66	SDG2	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-75	SDG2	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-84	SDG2	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-85	SDG2	null	null	1
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-93	SDG2	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-24	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-25	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-50	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-64	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-77	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-87	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-89	SDG7	null	null	1
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-92	SDG7	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-10	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-40	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-65	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-68	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-71	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-72	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-80	SDG5	null	null	1
Q03139	DO GENDER QUOTAS BREAK OR RAISE THE GLASS CEILING? Using evidence from France, this paper argues that gender quotas mechanically attract new women in politics but fail to trigger a self-sustained dynamics that would help women climb the ladder. I analyze the impact of two gender quotas which were first introduced in 2001 in municipalities above 3,500 inhabitants and extended in 2014 to municipalities between 1,000 and 3,500 inhabitants. They both imposed 50% of women in candidate lists. I find that they largely increased the share of female municipal councillors but did not lead to an increase in the number of women at the next hierarchical level: the position of mayor. 2018 Presses de Sciences Po. All rights reserved. Elections; Gender; Glass ceiling; Parity; Quotas  	L-96	SDG5	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-23	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-23	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-42	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-42	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-60	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-60	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-75	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-75	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-85	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-85	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-88	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-88	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-90	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-90	SDG13	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-93	SDG7	null	null	1
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-93	SDG13	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-23	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-23	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-42	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-42	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-60	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-60	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-75	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-75	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-85	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-85	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-88	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-88	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-90	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-90	SDG11	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-93	SDG6	null	null	1
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-93	SDG11	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-18	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-24	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-25	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-50	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-64	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-77	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-89	SDG3	null	null	1
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-92	SDG3	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-38	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-55	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-62	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-75	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-85	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-88	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-90	SDG4	null	null	1
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-93	SDG4	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-24	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-25	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-50	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-64	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-77	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-87	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-89	SDG5	null	null	1
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-92	SDG5	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-15	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-17	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-46	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-47	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-63	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-74	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-78	SDG4	null	null	1
Q103316	Political connections and higher education Do political connections affect investment in human capital? This paper studies the higher education decisions of politically connected and unconnected students during China's economic transition. Using the sequential introduction of reforms, I show that economic liberalization increased tertiary educational attainment, as well as sorting of students into different degree types depending on family background. Students whose parents were members of the Chinese Communist Party selected into relatively less prestigious vocational colleges with lower admissions standards. In contrast, politically unconnected individuals responded to the higher skill premium following the reforms by studying harder to obtain more demanding and sought-after university degrees. 2018 The Author Economics of Transition and Institutional Change 2018 The European Bank for Reconstruction and Development Published by Blackwell Publishing Ltd economic liberalization; higher education; Political connections communism; higher education; human capital; liberalization; market transition; political participation; political power; university sector; China  	L-86	SDG4	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-23	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-42	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-60	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-62	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-75	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-83	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-85	SDG3	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-88	SDG3	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-23	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-42	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-60	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-62	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-66	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-69	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-75	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-85	SDG8	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-93	SDG8	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-18	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-24	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-25	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-50	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-54	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-64	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-87	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-89	SDG6	null	null	1
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-92	SDG6	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-18	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-24	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-25	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-50	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-54	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-64	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-77	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-87	SDG10	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-89	SDG10	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-21	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-35	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-57	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-60	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-62	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-75	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-83	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-84	SDG8	null	null	1
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-93	SDG8	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-15	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-17	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-46	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-47	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-49	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-52	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-78	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-79	SDG4	null	null	1
Q062961	Adjusting content to individual student needs: Further evidence from an in-service teacher training program Adapting instruction to the specific needs of each student is a promising strategy to improve overall academic achievement. In this article, I study the impact of an intensive in-service teacher training program on reading skills offered to kindergarten teachers in France. The program modifies the lesson content and encourages teachers to adapt instruction to student needs by dividing the class according to initial achievement. While assessing impact is usually difficult due to the presence of ability bias and teacher selection, I show that in this context, a value-added model that controls for school and teacher characteristics constitutes a legitimate strategy to estimate the treatment effect. Results show that all students benefiting from the program progressed in reading skills at the end of the year. Besides, weaker students progressed faster on less-advanced competences (such as letter recognition), while stronger students improved their reading skills. This suggests that teachers adjusted content to students' needs. Finally, a cost-effectiveness analysis reveals that the program is approximately three times more cost-effective than reducing class size in France. 2016 Elsevier Ltd. Early childcare program; Inequality; Teacher training; Teaching practices and content child care; primary education; student; teacher training; France  	L-86	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-24	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-25	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-50	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-54	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-64	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-77	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-87	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-89	SDG4	null	null	1
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-92	SDG4	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-14	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-23	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-42	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-62	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-75	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-83	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-85	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-88	SDG13	null	null	1
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-90	SDG13	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-23	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-38	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-42	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-60	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-62	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-66	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-69	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-75	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-85	SDG12	null	null	1
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-93	SDG12	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-18	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-24	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-25	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-32	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-50	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-64	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-77	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-87	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-89	SDG14	null	null	1
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-92	SDG14	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-18	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-24	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-25	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-50	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-54	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-64	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-77	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-87	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-89	SDG3	null	null	1
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-92	SDG3	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-6	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-15	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-20	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-23	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-31	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-32	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-33	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-37	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-38	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-41	SDG11	null	null	1
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-42	SDG11	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-6	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-14	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-20	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-22	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-31	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-32	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-34	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-35	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-38	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-41	SDG3	null	null	1
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-42	SDG3	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-30	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-33	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-38	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-39	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-42	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-57	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-60	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-75	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-85	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-90	SDG16	null	null	1
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-93	SDG16	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-33	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-38	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-42	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-55	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-62	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-66	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-70	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-75	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-83	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-90	SDG10	null	null	1
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-93	SDG10	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-6	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-15	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-20	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-22	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-31	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-33	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-34	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-35	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-37	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-38	SDG11	null	null	1
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-41	SDG11	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-6	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-20	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-29	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-31	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-32	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-33	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-34	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-35	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-37	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-38	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-41	SDG3	null	null	1
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-42	SDG3	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-6	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-12	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-14	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-20	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-29	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-31	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-32	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-33	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-35	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-37	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-38	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-42	SDG9	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-30	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-35	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-38	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-42	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-60	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-62	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-66	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-69	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-70	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-75	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-83	SDG12	null	null	1
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-85	SDG12	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-23	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-30	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-38	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-42	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-60	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-66	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-70	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-75	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-84	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-85	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-88	SDG5	null	null	1
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-93	SDG5	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-6	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-15	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-20	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-22	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-29	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-32	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-33	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-34	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-35	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-37	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-38	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-41	SDG11	null	null	1
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-42	SDG11	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-6	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-15	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-20	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-22	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-29	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-31	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-33	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-34	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-35	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-37	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-38	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-41	SDG7	null	null	1
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-42	SDG7	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-23	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-30	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-38	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-42	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-55	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-60	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-70	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-75	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-83	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-85	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-88	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-90	SDG6	null	null	1
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-93	SDG6	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-23	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-30	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-38	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-42	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-60	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-62	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-66	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-75	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-83	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-85	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-88	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-90	SDG1	null	null	1
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-93	SDG1	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-6	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-15	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-20	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-22	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-23	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-29	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-31	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-32	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-33	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-34	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-35	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-37	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-38	SDG11	null	null	1
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-41	SDG11	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-6	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-15	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-20	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-22	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-29	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-31	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-32	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-33	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-34	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-35	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-37	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-38	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-41	SDG7	null	null	1
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-42	SDG7	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-6	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-15	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-20	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-22	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-25	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-29	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-31	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-32	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-33	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-34	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-35	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-37	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-38	SDG9	null	null	1
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-41	SDG9	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-6	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-12	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-14	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-15	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-20	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-29	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-31	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-32	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-33	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-34	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-37	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-38	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-41	SDG2	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-42	SDG2	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-21	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-23	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-23	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-30	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-30	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-38	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-38	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-42	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-42	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-60	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-60	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-62	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-66	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-66	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-70	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-70	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-75	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-75	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-83	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-83	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-84	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-84	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-85	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-85	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-91	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-91	SDG5	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-93	SDG4	null	null	1
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-93	SDG5	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-6	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-14	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-15	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-20	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-22	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-29	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-31	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-32	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-33	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-34	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-35	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-37	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-38	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-41	SDG7	null	null	1
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-42	SDG7	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-6	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-12	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-14	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-15	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-20	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-22	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-29	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-31	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-32	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-33	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-34	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-35	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-37	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-38	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-41	SDG12	null	null	1
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-42	SDG12	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-6	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-14	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-15	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-20	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-22	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-29	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-31	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-32	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-33	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-34	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-35	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-37	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-38	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-41	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-42	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-14	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-23	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-30	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-38	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-42	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-55	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-60	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-62	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-75	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-83	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-84	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-85	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-88	SDG11	null	null	1
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-93	SDG11	null	null	1
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-72	SDG9	null	1	null
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-20	SDG1	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-17	SDG11	null	1	null
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-40	SDG1	null	1	null
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-72	SDG16	null	1	null
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-64	SDG8	null	1	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-90	SDG16	null	1	null
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-29	SDG11	null	1	null
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-42	SDG9	null	1	null
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-47	SDG6	null	1	null
Q2028	An interdisciplinary approach to the study of extreme weather events: Large-scale atmospheric controls and insights from dynamical systems theory and statistical mechanics The workshop on 'Large-Scale Atmospheric Controls of Extreme Weather Events and Novel Predictability Pathways' gathered speakers with a wide range of backgrounds to foster such cross-disciplinary interactions. A specific focus was on identifying novel analysis techniques to describe large-scale atmospheric flows and their links to extreme weather events. Tim Woollings analyzed the eddy-driven jet stream's variability on daily to decadal time scales. He showed a complex interplay between these time scales, with decadal variations in jet speed modulating the shorter-term variability in the jet's latitudinal location. Lynn McMurdie focused in more detail on intense precipitation events associated with extratropical cyclones. Dynamical systems; Statistical mechanics; Storms; Analysis techniques; Atmospheric controls; Cross-disciplinary; Decadal timescale; Decadal variations; Extratropical cyclones; Extreme weather events; Intense precipitation; Weather information services  	L-72	SDG13	null	1	null
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-32	SDG7	null	1	null
Q2298	Intermittent flux from a sand filter for household wastewater and integrated solute transfer to the vadose zone Depending on the actual number of soil-based on-site wastewater treatment system (OWTS) in an area, on-site sanitation may be a significant source of pollutants and a threat to groundwater. Even in the case of a system functioning correctly, here, a sand filter substituted for the in-situ soil, as the treated effluent may reach to the water table, it is necessary evaluating in situ how much the sand and underneath soil respectively contribute to pollutant removal. On the plot of a household in a small rural community, the functioning of a real scale OWTS was monitored for 1.5 years. This system, composed of a septic tank connected to a 5 × 5 m 2 and 0.7-m thick aerobic sand filter was equipped with soil hydrodynamic probes (water content and matrix potential) during construction. By using the instantaneous profile method of water content, the intermittent infiltrated flux was determined across the sand-pack according to position and time. Treated water infiltrates into underneath soil acting as post-treatment. Quality of interstitial liquid from the sand and the soil was analysed each month on a 12-h pumping sample obtained through porous plates. Results of water fluxes and concentrations provide an estimate of the annual flux to the vadose zone and groundwater of metals, nutrients and some organic micro-pollutants (parabens and triclosan) through the OWTS and subsoil. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Colluvium; France; Groundwater; Monitoring; On-site sanitation; Organic micro-pollutant; Paraben; Purification; Soil; SUVA; Triclosan chemical substance; domestic waste; effluent; filter; flux measurement; groundwater; organic pollutant; paraben; pollution monitoring; purification; sanitation; solute transport; vadose zone; wastewater; wastewater treatment; wastewater treatment plant; France; 4 hydroxybenzoic acid ester; ground water; metal; silicon dioxide; triclosan; analysis; family size; filtration; procedures; soil; waste water; water management; water pollutant; Family Characteristics; Filtration; Groundwater; Metals; Parabens; Silicon Dioxide; Soil; Triclosan; Waste Water; Water Pollutants, Chemical; Water Purification  	L-21	SDG6	null	1	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-35	SDG2	null	1	null
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-32	SDG3	null	1	null
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-70	SDG16	null	1	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-47	SDG8	null	1	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-63	SDG16	null	1	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-92	SDG11	null	1	null
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-72	SDG8	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-72	SDG3	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-72	SDG10	null	1	null
Q011485	Pathways toward zero-carbon electricity required for climate stabilization This paper provides pathways of the carbon content of electricity extracted from the Intergovernmental Panel on Climate Change's fifth Assessment Report scenarios database. It demonstrates three policy-relevant aspects of the carbon content of electricity that are implicit in most integrated assessment model results but under-discussed in academia and the policy debate. First, climate stabilization at any level from 1.5 °C to 3 °C requires the carbon content of electricity to decrease quickly and become almost carbon-free before the end of the century. As such, the question for policy makers is not whether to decarbonize electricity but when and how to do so. Second, decarbonization of electricity is still possible and required if some of the key zero-carbon technologies—such as nuclear power or carbon capture and storage—turn out to be unavailable. Third, progressive decarbonization of electricity is part of every country's cost-effective means of contributing to climate stabilization. The pathways of the carbon content of electricity reported here can be used to benchmark existing decarbonization targets, such as those set by the European Energy Roadmap or inform new policies in other countries. They can also be used to assess the desirable uptake rates of electric and plug-in hybrid vehicles, electric stoves and heat pumps, industrial electric furnaces, or other electrification technologies. 2018 Carbon intensity; Climate change mitigation; Life cycle assessment; Power supply; Renewable energy Carbon capture; Cost effectiveness; Decarbonization; Electric furnaces; Electric power systems; Industrial stoves; Life cycle; Nuclear fuels; Plug-in hybrid vehicles; Stabilization; Carbon intensity; Climate change mitigation; Life Cycle Assessment (LCA); Power supply; Renewable energies; Climate change; benchmarking; carbon emission; database; electricity; electricity supply; environmental assessment; environmental policy; European Union; integrated approach; Intergovernmental Panel on Climate Change; life cycle analysis; mitigation; policy making  	L-90	SDG12	null	1	null
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-21	SDG5	null	1	null
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-62	SDG4	null	1	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-32	SDG1	null	1	null
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-52	SDG3	null	1	null
Q083000	Adjusting Your Dreams? High School Plans and Dropout Behaviour At the end of middle school, many low-achieving students realise that they do not have the ability to get into selective high school programmes, which may be a source of disengagement and eventually lead them to drop out of high school. Based on a randomised controlled trial, this article shows that a series of meetings facilitated by the school principals can help low-achievers to formulate educational objectives better suited to their academic aptitudes. By changing the high school plans of the less realistic students, the intervention reduces grade repetition and dropout by 25% to 40%. 2015 Royal Economic Society academic performance; educational development; psychology; secondary education; student  	L-32	SDG4	null	1	null
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-93	SDG12	null	1	null
Q103307	Girls' comparative advantage in reading can largely explain the gender gap in math-related fields Gender differences in math performance are now small in developed countries and they cannot explain on their own the strong underrepresentation of women in math-related fields. This latter result is however no longer true once gender differences in reading performance are also taken into account. Using individual-level data on 300,000 15-y-old students in 64 countries we show that the difference between a student performance in reading and math is 80% of a standard deviation (SD) larger for girls than boys a magnitude considered as very large. When this difference is controlled for the gender gap in students' intentions to pursue math-intensive studies and careers is reduced by around 75% while gender gaps in self-concept in math declared interest for math or attitudes toward math entirely disappear. These latter variables are also much less able to explain the gender gap in intentions to study math than is students' difference in performance betweenmath and reading. These results are in line with choice models in which educational decisions involve intraindividual comparisons of achievement and self-beliefs in different subjects as well as cultural norms regarding gender. To directly show that intraindividual comparisons of achievement impact students' intended careers we use differences across schools in teaching resources dedicated to math and reading as exogenous variations of students' comparative advantage for math. Results confirm that the comparative advantage in math with respect to reading at the time of making educational choices plays a key role in the process leading to women's underrepresentation in math-intensive fields. 2019 National Academy of Sciences. All rights reserved. Comparative advantage; Gender gap; Math-intensive fields; Students' achievement achievement; article; career; child; controlled study; female; gender; girl; human; human experiment; male; student; teaching  	L-32	SDG5	null	1	null
Q113304	Long-Term Impacts of Conditional Cash Transfers: Review of the Evidence Conditional Cash Transfer (CCT) programs, started in the late 1990s in Latin America, have become the antipoverty program of choice in many developing countries in the region and beyond. This paper reviews the literature on their long-term impacts on human capital and related outcomes observed after children have reached a later stage of their life cycle, focusing on two life-cycle transitions. The first includes children exposed to CCTs in utero or during early childhood who have reached school ages. The second includes children exposed to CCTs during school ages who have reached young adulthood. Most studies find positive long-term effects on schooling, but fewer find positive impacts on cognitive skills, learning, or socio-emotional skills. Impacts on employment and earnings are mixed, possibly because former beneficiaries were often still too young. A number of studies find estimates that are not statistically different from zero, but for which it is often not possible to be confident that this is due to an actual lack of impact rather than to the methodological challenges facing all long-term evaluations. Developing further opportunities for analyses with rigorous identification strategies for the measurement of long-term impacts should be high on the research agenda. As original beneficiaries age, this should also be increasingly possible, and indeed important before concluding whether or not CCTs lead to sustainable poverty reduction. The Author(s) 2019. Published by Oxford University Press on behalf of the International Bank for Reconstruction and Development / THE WORLD BANK. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs licence (http://creativecommons.org/licenses/by-nc-nd/4.0/), which permits noncommercial reproduction and distribution of the work, in any medium, provided the original work is not altered or transformed in any way, and that the work is properly cited. Conditional Cash Transfers (CCTs); Long-term impacts; PROGRESA developing world; employment; human capital; poverty alleviation; research; skilled labor; social impact; social policy; Latin America  	L-72	SDG8	null	1	null
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-47	SDG14	null	1	null
Q181302	Influence of construction material uncertainties on residential building LCA reliability Life cycle assessment (LCA) is widely used to evaluate the environmental impacts of buildings, but due to uncertainties, the final results can be unreliable. To increase the reliability of LCA results, this study identifies the building materials that have the largest relative contribution to buildings' impacts and uncertainties. To do so, the impacts of 15 single-family houses and 15 multi-family building projects situated in France are evaluated. Only the uncertainties related to input parameters for building materials are considered (service life, characterization factors and quantity). The results obtained in this study show that LCA will still be able to distinguish significantly between two projects if their difference is higher than approximately 20%. Furthermore, the impacts of the buildings' exploitation phase do not show any correlations with the impacts related to the construction materials. The exploitation phase dominates the non-renewable energy consumption while waste impacts are most influenced by building materials. The contribution to global warming potential is shared between both phases. Finally, reinforced concrete was identified as the largest contributor to the environmental impact of both building types. In contrast, insulation materials and non-structural wood were the largest contributors to the uncertainties of the final results for single-family houses and multi-family buildings, respectively. 2016 Elsevier Ltd Building LCA; Relative contribution; Uncertainties Buildings; Characterization; Construction; Energy utilization; Environmental impact; Global warming; Houses; Life cycle; Reinforced concrete; Characterization factors; Global warming potential; Influence of construction; Insulation materials; Life Cycle Assessment (LCA); Relative contribution; Residential building; Uncertainties; Building materials  	L-72	SDG7	null	1	null
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-72	SDG2	null	1	null
Q202275	The biogeochemical imprint of human metabolism in Paris Megacity: A regionalized analysis of a water-agro-food system Megacities are facing a twofold challenge regarding resources: (i) ensure their availability for a growing urban population and (ii) limit the impact of resource losses to the environment. This paper focuses on two essential resources – nitrogen and phosphorus – and challenges their sustainable management in the water-agro-food system of Paris Megacity. An in-depth analysis of the nitrogen and phosphorus imprint of Paris Megacity was conducted, originally centered on human metabolism through consumption and excretion of these two elements. Upstream, the whole agricultural production that feeds Paris Megacity was scrutinized and nitrogen and phosphorus flows in the agro-system were fully documented. Downstream, the analysis of solid waste and wastewater management in Paris Megacity showed the fate of nitrogen and phosphorus imported into the city. Paris Megacity appears to rely on a very complex and international agro-food system, requiring high levels of chemical fertilizers and strongly impacting the environment through nutrient environmental losses. On the other hand, solid waste and wastewater management appears to be mostly disconnected from the agro-food system: even if the release of nitrogen and phosphorus into the environment has largely decreased in recent years, their recycling rate remains very low. This overview of the water-agro-food system of Paris Megacity suggests that an optimal management of nitrogen and phosphorus in the three subsystems (agriculture, waste management and sanitation) should be integrated within a comprehensive approach linking agriculture and urban residues. This analysis thus constitutes a groundwork on which paradigm shift scenarios of the global water-agro-food system could be constructed. 2018 Elsevier B.V. Biogeochemical imprint; Megacity; Nitrogen cycle; Phosphorus cycle; Urban metabolism; Water-agro-food system Agriculture; Biogeochemistry; Chemical analysis; Fertilizers; Metabolism; Nitrogen; Phosphorus; Physiology; Solid wastes; Sustainable development; Waste management; Wastewater reclamation; Agro foods; Biogeochemical; Megacities; Nitrogen cycles; Phosphorus cycles; Urban metabolisms; Rivers; biogeochemistry; environmental impact assessment; human activity; megacity; nitrogen cycle; phosphorus; resource availability; sustainability; sustainable development; France; Ile de France; Paris; Ville de Paris  	L-72	SDG12	null	1	null
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-63	SDG2	null	1	null
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-20	SDG10	null	1	null
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-72	SDG16	null	1	null
Q02hal01941092	Urban planning 1.0. Survey of a commune in Greater Paris With Greater Paris, construction has gotten off to a flying start: housing, facilities, infrastructure. This book presents the transformations of a commune in eastern Paris, formerly in the 2nd ring road, which tomorrow will be served by a new Grand Paris Express station. The author, who has lived in this commune for 40 years and is a former researcher at the CNRS (French National Center for Scientific Research), uses his knowledge to develop a new approach, a political economy of detail . The project is to come out of the great frescoes - from one decade to the next - that explain things in a nutshell without showing how history is written and what impact it has had on the inhabitants. Cities are certainly the product of a few structuring programs, but also of a very large number of ordinary operations that, repeated, transform a street, a neighborhood and finally explain that a city is changing. To carry out this project, the author looks at his city from several points of view. In turn, he measures the number of constructions in progress; it is a vertiginous acceleration of the pace compared to the past and a total shift from the objective of moderate growth. With the procedure of the local urban plan, it studies the development of a public policy. It describes the main construction operations that have been or are being carried out, and the active promoters: real estate intermediaries and medium-sized builders have an important place in it. A specialist in network infrastructure, the author sheds new light on the sector by mobilizing the categories of utility regulation: transparency, equality, asymmetry, capture, reasonable profit. Finally, based on the documents kept by the mortgage department, he looks at the real economy of a few flagship operations. What is the level of urban rents, how do they compare with operating margins? This book, rich in information and diverse points of view, also questions the role of elected officials 35 years after decentralization. It sheds new light on the management of housing policy in Greater Paris. It demonstrates through significant short stories, such as 400 meters of soft lanes in 17 years , that there can be no change without vision and good institutions . Here, the book joins the national debate on rising housing prices. The data produced show how prices - and thus increases - are formed and on which link action should be taken; they finally help to measure the extent of the road to be travelled in order to design sustainable cities. Urban planning , Greater Paris , Grand Paris , etc.  	L-80	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-84	SDG8	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-84	SDG12	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-90	SDG8	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-90	SDG12	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-47	SDG16	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-52	SDG16	null	1	null
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-32	SDG8	null	1	null
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-50	SDG8	null	1	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-32	SDG6	null	1	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-77	SDG6	null	1	null
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-32	SDG11	null	1	null
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-64	SDG11	null	1	null
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-72	SDG2	null	1	null
Q734	Land Sharing vs Land Sparing to Conserve Biodiversity: How Agricultural Markets Make the Difference In this paper, we model the supply and demand for agricultural goods and assess and compare how welfare, land use, and biodiversity are affected under intensive and extensive farming systems at market equilibrium instead of at exogenous production levels. As long as demand is responsive to price, and intensive farming has lower production costs, there exists a rebound effect (larger market size) of intensive farming. Intensive farming is then less beneficial to biodiversity than extensive farming is, except when there is a high degree of convexity between biodiversity and yield. On the other hand, extensive farming leads to higher prices and smaller quantities for consumers. Depending on parameter values, it may increase or decrease agricultural producer profits. Implementing “active” land sparing by zoning some land for agriculture and other land for conservation could overcome the rebound effect of intensive farming, but we show that farmers have then incentives to encroach on land zoned for conservation, with higher incentives under intensive farming. We also show that the primary effect of the higher prices associated with extensive farming is a reduction of animal feed production, which has a higher price elasticity of demand, whereas less of an effect is observed on plant-based food production and almost no effect is observed on biofuel production if there are mandatory blending policies. 2016, Springer International Publishing Switzerland. Agriculture; Biodiversity; Conservation; Land use; Markets; Welfare  	L-96	SDG2	null	1	null
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-32	SDG7	null	1	null
Q754	Energy consumption and activity patterns: An analysis extended to total time and energy use for French households Household lifestyles, and activity patterns in particular, greatly influence household energy use. In this paper we analyse the disparities in current activity patterns and related energy consumptions and expenditures of households, for a comprehensive set of everyday activities covering 24 h. Thanks to detailed data on energy consumption by end use, we are able to allocate the total of household energy consumptions to the appropriate activities. We comment on average energy and expenditure intensities of time uses of the total population as well as of income, household-composition and housing-type subgroups. Income, an obvious driver of energy and expenditure intensities, is revealed to influence time use as well. Household composition and housing type are also associated with substantial variations in activity patterns and in the energy and expenditure intensities of activities, even within a given income group. Indeed, sometimes the variations associated with income are smaller than the variations associated with other variables. We therefore underline the importance of household disaggregation in household energy analyses, to properly account for such disparities. 2017 Elsevier Ltd Energy consumption; Household consumption; Household heterogeneity; Time use Housing; Activity patterns; Disaggregation; Household Consumption; Household energy; Household energy use; Household heterogeneity; Substantial variations; Time use; Energy utilization; energy use; heterogeneity; household energy; household expenditure; household income; household structure; lifestyle; temporal analysis; France  	L-54	SDG7	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-23	SDG11	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-42	SDG11	null	1	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-47	SDG13	null	1	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-47	SDG14	null	1	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-78	SDG13	null	1	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-78	SDG14	null	1	null
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-14	SDG11	null	1	null
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-31	SDG11	null	1	null
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-29	SDG3	null	1	null
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-37	SDG3	null	1	null
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-72	SDG11	null	1	null
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-96	SDG11	null	1	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-22	SDG9	null	1	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-34	SDG9	null	1	null
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-32	SDG10	null	1	null
Q3052	Economic and public health consequences of delayed access to medical care for migrants living with HIV in France In 2013, migrants accounted for 46% of newly diagnosed cases of HIV (human immunodeficiency virus) infection in France. These populations meet with specific obstacles leading to late diagnosis and access to medical care. Delayed access to care (ATC) for HIV-infected migrants reduces their life expectancy and quality of life. Given the reduction of infectivity under antiretroviral (ARV) treatment, delayed ATC for HIV-infected migrants may also hinder the control of the HIV epidemic. The objective of this study is to measure the public health and economic consequences of delayed ATC for migrants living with HIV in France. Using a healthcare payer perspective, our model compares the lifetime averted infections and costs of early vs. late ATC for migrants living with HIV in France. Early and late ATC are defined by an entry into care with a CD4 cell count of 350 and 100/mm3, respectively. Our results show that an early ATC is dominant, even in the worst-case scenario. In the most favorable scenario, early ATC generates an average net saving of €198,000 per patient, and prevents 0.542 secondary infection. In the worst-case scenario, early ATC generates an average net saving of €32,000 per patient, and prevents 0.299 secondary infection. These results are robust to various adverse changes in key parameters and to a definition of late ATC as an access to care at a CD4 level of 200/mm3. In addition to individual health benefits, improving ATC for migrants living with HIV proves efficient in terms of public health and economics. These results stress the benefit of ensuring early ATC for all individuals living with HIV in France. 2017, Springer-Verlag Berlin Heidelberg. Access to care; France; HIV/AIDS; Migrant populations; Public policy adult; Article; CD4 lymphocyte count; cost control; delayed diagnosis; female; France; health care access; health care cost; health care policy; heterosexuality; hospitalization; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; Human immunodeficiency virus infection; infection prevention; life expectancy; major clinical study; male; mandatory reporting; medical care; medical examination; migrant; priority journal; public health; quality of life; secondary infection; sexual behavior; sexual intercourse; therapy delay; unprotected sex; economics; Human immunodeficiency virus infection; migration; France; HIV Infections; Humans; Life Expectancy; Public Health; Quality of Life; Transients and Migrants  	L-92	SDG10	null	1	null
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-47	SDG14	null	1	null
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-78	SDG14	null	1	null
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-72	SDG1	null	1	null
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-72	SDG3	null	1	null
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-96	SDG1	null	1	null
Q17736	Aligning domestic policies with international coordination in a post-Paris global climate regime: A case for China The Paris COP-21 reached a climate agreement on 2-degree global emissions stabilisation target. However, the likelihood of successfully implementing a legally binding global climate treaty will depend to a large degree on the macroeconomic impacts of different policy options on developing and emerging economies. It is thus crucial to evaluate the transition costs of implementing different climate policy architectures under socioeconomic and technological uncertainties from a multiregional perspective. Here we use a hybrid computable general equilibrium model, in which sub-optimalities, infrastructural inertia and technological uncertainties are explicitly introduced, to quantify the trajectories of variation in transitions costs under a range of climate policy scenarios in both Annex I and developing nations. The policy architectures are based around the implementation of the ‘streamlined Paris Pledges’ (SPP) in developing countries with a particular focus on China and India. Our results indicate that the distributional effects should be taken into account by policymakers through extension of SPP to 2050 as global climate policies may have asymmetrical economic impacts between Annex I and developing countries. A first-best policy of global cap-and-trade scheme alone could be welfare-deteriorating for some parties, reflected by a significant reduction in macroeconomic growth rate over the course of the next decades. Modelling results also suggest that articulating both global and national policies in a multiregional climate deal can provide a palatable solution for countries like China as this would allow for significant reduction in the economic losses associated with a unique-carbon-price global climate policy. This hybrid approach is also aligned with specific development priorities in developing and emerging countries by providing flexibility to their domestic policy framework, which expects to facilitate the transition to low carbon growth trajectory by encouraging intersectoral coordination. Last, procrastination of technical change and delayed structural reform for decarbonising economy would entail significantly higher transition costs for developing countries in case of stringent climate policy due to the economic competitiveness forgone as a result of exorbitant carbon prices in the longer term. Relevant policy options and research perspectives are discussed accordingly. 2017 Elsevier Inc. China; Global climate policy; International and domestic coordination; National complementary policies; Paris Agreement; Second-best modelling Climate change; Costs; Developing countries; Economics; Losses; China; Climate policy scenarios; Computable general equilibrium model; Economic competitiveness; Global climates; International and domestic coordination; International coordination; Technological uncertainty; Climate models; developing world; emission control; emissions trading; environmental economics; environmental policy; global climate; international agreement; macroeconomics; policy analysis; policy approach; policy implementation; targeting; China  	L-96	SDG3	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-65	SDG16	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-72	SDG16	null	1	null
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-32	SDG1	null	1	null
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-64	SDG1	null	1	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-72	SDG8	null	1	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-96	SDG8	null	1	null
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-47	SDG1	null	1	null
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-78	SDG1	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-39	SDG1	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-70	SDG1	null	1	null
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-15	SDG3	null	1	null
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-47	SDG3	null	1	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-23	SDG10	null	1	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-85	SDG10	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-46	SDG12	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-47	SDG2	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-47	SDG11	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-78	SDG2	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-78	SDG11	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-78	SDG12	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-86	SDG2	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-86	SDG11	null	1	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-86	SDG12	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-23	SDG11	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-42	SDG15	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-60	SDG11	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-84	SDG11	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-84	SDG15	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-90	SDG15	null	1	null
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-32	SDG8	null	1	null
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-50	SDG8	null	1	null
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-87	SDG8	null	1	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-23	SDG10	null	1	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-88	SDG10	null	1	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-90	SDG10	null	1	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-32	SDG11	null	1	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-50	SDG11	null	1	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-64	SDG11	null	1	null
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-33	SDG11	null	1	null
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-39	SDG11	null	1	null
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	L-90	SDG11	null	1	null
Q2312	Evaluation of contaminant retention in the soil of sustainable drainage systems: methodological reflections on the determination of sorption isotherms Runoff infiltration in Sustainable Drainage Systems enables the interception of a part of urban contaminant fluxes owing to several processes. The soil's ability to retain dissolved pollutants is generally assessed via sorption isotherms obtained from batch studies; however, the experimental points are not always in the same range as runoff concentrations. The present work (i) explores the consequences of modelling runoff–soil interactions from out-of-range equilibrium concentrations and (ii) proposes an improved method to ensure that experimental points fall within the desired range. Uncertainty analysis demonstrates that for a non-linear isotherm, using an extrapolated relationship may introduce significant biases in the ensuing estimations. Therefore, the proposed method consists of anticipating the equilibrium state of batch tests to accurately set the experimental conditions and reach appropriate concentrations. It is successfully applied to the determination of the sorption properties of copper and zinc onto three soils with different electrolyte solutions, as well as those of bisphenol A and three alkylphenols onto one soil. The contrasting affinities between the studied species and the soil materials could be related to their intrinsic properties and the soils' pedological parameters, as well as the presence of salt or dissolved organic ligands which partially inhibited metal sorption.  	L-65	SDG11	null	1	null
Q2312	Evaluation of contaminant retention in the soil of sustainable drainage systems: methodological reflections on the determination of sorption isotherms Runoff infiltration in Sustainable Drainage Systems enables the interception of a part of urban contaminant fluxes owing to several processes. The soil's ability to retain dissolved pollutants is generally assessed via sorption isotherms obtained from batch studies; however, the experimental points are not always in the same range as runoff concentrations. The present work (i) explores the consequences of modelling runoff–soil interactions from out-of-range equilibrium concentrations and (ii) proposes an improved method to ensure that experimental points fall within the desired range. Uncertainty analysis demonstrates that for a non-linear isotherm, using an extrapolated relationship may introduce significant biases in the ensuing estimations. Therefore, the proposed method consists of anticipating the equilibrium state of batch tests to accurately set the experimental conditions and reach appropriate concentrations. It is successfully applied to the determination of the sorption properties of copper and zinc onto three soils with different electrolyte solutions, as well as those of bisphenol A and three alkylphenols onto one soil. The contrasting affinities between the studied species and the soil materials could be related to their intrinsic properties and the soils' pedological parameters, as well as the presence of salt or dissolved organic ligands which partially inhibited metal sorption.  	L-72	SDG11	null	1	null
Q2312	Evaluation of contaminant retention in the soil of sustainable drainage systems: methodological reflections on the determination of sorption isotherms Runoff infiltration in Sustainable Drainage Systems enables the interception of a part of urban contaminant fluxes owing to several processes. The soil's ability to retain dissolved pollutants is generally assessed via sorption isotherms obtained from batch studies; however, the experimental points are not always in the same range as runoff concentrations. The present work (i) explores the consequences of modelling runoff–soil interactions from out-of-range equilibrium concentrations and (ii) proposes an improved method to ensure that experimental points fall within the desired range. Uncertainty analysis demonstrates that for a non-linear isotherm, using an extrapolated relationship may introduce significant biases in the ensuing estimations. Therefore, the proposed method consists of anticipating the equilibrium state of batch tests to accurately set the experimental conditions and reach appropriate concentrations. It is successfully applied to the determination of the sorption properties of copper and zinc onto three soils with different electrolyte solutions, as well as those of bisphenol A and three alkylphenols onto one soil. The contrasting affinities between the studied species and the soil materials could be related to their intrinsic properties and the soils' pedological parameters, as well as the presence of salt or dissolved organic ligands which partially inhibited metal sorption.  	L-80	SDG11	null	1	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-45	SDG13	null	1	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-74	SDG13	null	1	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-78	SDG13	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-46	SDG7	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-46	SDG13	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-46	SDG16	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-47	SDG7	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-47	SDG13	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-47	SDG16	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-78	SDG7	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-78	SDG13	null	1	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-78	SDG16	null	1	null
Q04889	Intermittent large amplitude internal waves observed in Port Susan, Puget Sound A previously unreported internal tidal bore, which evolves into solitary internal wave packets, was observed in Port Susan, Puget Sound, and the timing, speed, and amplitude of the waves were measured by CTD and visual observation. Acoustic Doppler current profiler (ADCP) measurements were attempted, but unsuccessful. The waves appear to be generated with the ebb flow along the tidal flats of the Stillaguamish River, and the speed and width of the resulting waves can be predicted from second-order KdV theory. Their eventual dissipation may contribute significantly to surface mixing locally, particularly in comparison with the local dissipation due to the tides. Visually the waves appear in fair weather as a strong foam front, which is less visible the farther they propagate. 2017 Elsevier Ltd Coastal waters; Internal waves; Korteweg-de Vries equation; Mixing processes; Tidal effects Acoustic Doppler Current Profiler; coastal water; comparative study; equation; internal wave; intertidal environment; mixing; reaction kinetics; tidal flat; Puget Sound; Stillaguamish River; United States; Washington [United States]  	L-72	SDG14	null	1	null
Q04889	Intermittent large amplitude internal waves observed in Port Susan, Puget Sound A previously unreported internal tidal bore, which evolves into solitary internal wave packets, was observed in Port Susan, Puget Sound, and the timing, speed, and amplitude of the waves were measured by CTD and visual observation. Acoustic Doppler current profiler (ADCP) measurements were attempted, but unsuccessful. The waves appear to be generated with the ebb flow along the tidal flats of the Stillaguamish River, and the speed and width of the resulting waves can be predicted from second-order KdV theory. Their eventual dissipation may contribute significantly to surface mixing locally, particularly in comparison with the local dissipation due to the tides. Visually the waves appear in fair weather as a strong foam front, which is less visible the farther they propagate. 2017 Elsevier Ltd Coastal waters; Internal waves; Korteweg-de Vries equation; Mixing processes; Tidal effects Acoustic Doppler Current Profiler; coastal water; comparative study; equation; internal wave; intertidal environment; mixing; reaction kinetics; tidal flat; Puget Sound; Stillaguamish River; United States; Washington [United States]  	L-80	SDG14	null	1	null
Q04889	Intermittent large amplitude internal waves observed in Port Susan, Puget Sound A previously unreported internal tidal bore, which evolves into solitary internal wave packets, was observed in Port Susan, Puget Sound, and the timing, speed, and amplitude of the waves were measured by CTD and visual observation. Acoustic Doppler current profiler (ADCP) measurements were attempted, but unsuccessful. The waves appear to be generated with the ebb flow along the tidal flats of the Stillaguamish River, and the speed and width of the resulting waves can be predicted from second-order KdV theory. Their eventual dissipation may contribute significantly to surface mixing locally, particularly in comparison with the local dissipation due to the tides. Visually the waves appear in fair weather as a strong foam front, which is less visible the farther they propagate. 2017 Elsevier Ltd Coastal waters; Internal waves; Korteweg-de Vries equation; Mixing processes; Tidal effects Acoustic Doppler Current Profiler; coastal water; comparative study; equation; internal wave; intertidal environment; mixing; reaction kinetics; tidal flat; Puget Sound; Stillaguamish River; United States; Washington [United States]  	L-96	SDG14	null	1	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-32	SDG8	null	1	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-64	SDG8	null	1	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-92	SDG8	null	1	null
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-14	SDG11	null	1	null
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-29	SDG11	null	1	null
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-32	SDG11	null	1	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-10	SDG16	null	1	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-72	SDG16	null	1	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-96	SDG16	null	1	null
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-32	SDG3	null	1	null
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-54	SDG3	null	1	null
Q042991	The effect of ambient temperature shocks during conception and early pregnancy on later life outcomes A large body of research has recently shown that early life or in utero shocks, especially climatic shocks, may affect long-run human capital outcomes. Most of these effects are assumed to be biological – including poor nutrition during critical windows of fetal development, or through increased maternal stress. However, in addition to these biological effects, climatic conditions at the time of conception may also cause changes in parental behavior, not only affecting the mix of parents who conceive, but also the characteristics of the children once born. This paper explores whether increases in ambient temperature at the time of conception, while in utero, or after birth affect educational and health outcomes as adults. Using Census and Demographic and Health Survey data from sub-Saharan Africa, we show that individuals conceived during high temperatures have higher educational attainment and literacy. In addition, we find evidence of temperature effects at other times in utero, especially during the first trimester. We then explore the biological and behavioral mechanisms through which this effect may occur, including heat-induced changes in sexual behavior, differences in parental characteristics, and intensified fetal selection. We conclude that fetal selection is the most likely mechanism driving our result. 2017 Elsevier B.V. Conception; Fertility; Fetal origins; Human capital; Temperature embryonic development; fertility; health impact; human capital; pregnancy; temperature effect; Sub-Saharan Africa  	L-87	SDG3	null	1	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-65	SDG3	null	1	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-65	SDG7	null	1	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-72	SDG3	null	1	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-80	SDG7	null	1	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-96	SDG3	null	1	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-96	SDG7	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-32	SDG13	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-50	SDG13	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-64	SDG13	null	1	null
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-47	SDG2	null	1	null
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-78	SDG2	null	1	null
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-86	SDG2	null	1	null
Q142927	A Theory of Political Entrenchment Can an incumbent political party increase its chances at re-election by implementing inefficient policies that harm its constituency? This paper studies the possibility of such a phenomenon, which we label political entrenchment. We use a two-party dynamic model of redistribution with probabilistic voting. Political entrenchment by the Left occurs only if incumbency rents are sufficiently high. Low-skill citizens may vote for this party even though they rationally expect the adoption of these policies. We discuss: the possibility of entrenchment by the Right; the scope for commitment to avoid entrenchment policies; and the effect of state capacity, income inequality and party popularity on the likelihood of entrenchment. We illustrate our theory with a number of historical examples. 2014 Royal Economic Society election; modeling; party politics; political theory; voting behavior  	L-40	SDG10	null	1	null
Q142927	A Theory of Political Entrenchment Can an incumbent political party increase its chances at re-election by implementing inefficient policies that harm its constituency? This paper studies the possibility of such a phenomenon, which we label political entrenchment. We use a two-party dynamic model of redistribution with probabilistic voting. Political entrenchment by the Left occurs only if incumbency rents are sufficiently high. Low-skill citizens may vote for this party even though they rationally expect the adoption of these policies. We discuss: the possibility of entrenchment by the Right; the scope for commitment to avoid entrenchment policies; and the effect of state capacity, income inequality and party popularity on the likelihood of entrenchment. We illustrate our theory with a number of historical examples. 2014 Royal Economic Society election; modeling; party politics; political theory; voting behavior  	L-72	SDG10	null	1	null
Q142927	A Theory of Political Entrenchment Can an incumbent political party increase its chances at re-election by implementing inefficient policies that harm its constituency? This paper studies the possibility of such a phenomenon, which we label political entrenchment. We use a two-party dynamic model of redistribution with probabilistic voting. Political entrenchment by the Left occurs only if incumbency rents are sufficiently high. Low-skill citizens may vote for this party even though they rationally expect the adoption of these policies. We discuss: the possibility of entrenchment by the Right; the scope for commitment to avoid entrenchment policies; and the effect of state capacity, income inequality and party popularity on the likelihood of entrenchment. We illustrate our theory with a number of historical examples. 2014 Royal Economic Society election; modeling; party politics; political theory; voting behavior  	L-96	SDG10	null	1	null
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-32	SDG2	null	1	null
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-50	SDG2	null	1	null
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-92	SDG2	null	1	null
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-32	SDG13	null	1	null
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-50	SDG13	null	1	null
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-64	SDG13	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-15	SDG5	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-17	SDG5	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-47	SDG5	null	1	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-52	SDG5	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-15	SDG11	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-63	SDG11	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-74	SDG11	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-78	SDG11	null	1	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-14	SDG8	null	1	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-31	SDG8	null	1	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-32	SDG8	null	1	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-42	SDG8	null	1	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-32	SDG7	null	1	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-50	SDG7	null	1	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-64	SDG7	null	1	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-92	SDG7	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-23	SDG11	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-42	SDG11	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-75	SDG11	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-84	SDG11	null	1	null
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-23	SDG10	null	1	null
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-30	SDG10	null	1	null
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-57	SDG10	null	1	null
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-85	SDG10	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-65	SDG4	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-71	SDG4	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-72	SDG4	null	1	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-80	SDG4	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-23	SDG14	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-60	SDG14	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-85	SDG14	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-90	SDG14	null	1	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-50	SDG9	null	1	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-64	SDG9	null	1	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-77	SDG9	null	1	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-87	SDG9	null	1	null
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-30	SDG13	null	1	null
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-38	SDG13	null	1	null
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-70	SDG13	null	1	null
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-93	SDG13	null	1	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-23	SDG2	null	1	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-39	SDG2	null	1	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-69	SDG2	null	1	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-90	SDG2	null	1	null
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-20	SDG15	null	1	null
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-47	SDG15	null	1	null
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-74	SDG15	null	1	null
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-78	SDG15	null	1	null
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-86	SDG15	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-23	SDG9	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-42	SDG9	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-60	SDG9	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-88	SDG9	null	1	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-90	SDG9	null	1	null
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-24	SDG15	null	1	null
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-32	SDG15	null	1	null
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-50	SDG15	null	1	null
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-64	SDG15	null	1	null
Q1260	Stress generated by the freeze–thaw process in open cracks of rock walls: empirical model for tight limestone In mountainous areas, freezing is a prominent phenomenon for weathering processes in rock walls. A freezing front penetrates rock crack networks and causes its propagation. To study the evolution of rock mass stability, a suitable model of stress generated by freezing in open rock cracks is needed. This stress evaluated by the simple volume expansion model in a closed crack is too high to be realistic. In this paper, we present an assessment method for this stress and some results. Different experiments on notched limestone specimens submitted to freeze–thaw cycles were performed. Three different tight limestones (Larrys, Chamesson, Pierre de Lens) were tested. Actually, the stress generated by freezing begins to grow at the top of the notch where an ice plug is created and makes it possible for higher stresses to develop in deeper parts of the notch. Consequently, the stress induced by freezing depends on the geometry of the open crack represented by the notch. This value is, however, limited by the permeability of the surrounding rock matrix. A model of the stress evolution generated by freezing along an open crack was established and its envelope curve, named maximum stress, was parameterized. This maximum stress generated by freezing along the crack is completely defined by knowledge of the pore network of the limestone matrix and the geometry of the crack. 2016, Springer-Verlag Berlin Heidelberg. Crack; Freezing alteration; Limestone; Stress model Cracks; Freezing; Limestone; Rocks; Thawing; Empirical model; Mountainous area; Rock mass stability; Stress evolution; Stress modeling; Surrounding rock; Volume expansion; Weathering process; Weathering; assessment method; crack; freeze-thaw cycle; geometry; limestone; modeling; rock; stress; wall; weathering  	L-92	SDG15	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-23	SDG12	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-42	SDG12	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-60	SDG12	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-75	SDG12	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-90	SDG12	null	1	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-24	SDG7	null	1	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-32	SDG7	null	1	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-50	SDG7	null	1	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-64	SDG7	null	1	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-92	SDG7	null	1	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-30	SDG4	null	1	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-33	SDG4	null	1	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-42	SDG4	null	1	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-60	SDG4	null	1	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-69	SDG4	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-30	SDG3	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-38	SDG3	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-39	SDG3	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-70	SDG3	null	1	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-90	SDG3	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-38	SDG13	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-42	SDG13	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-62	SDG13	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-69	SDG13	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-84	SDG13	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-90	SDG13	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-23	SDG3	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-42	SDG3	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-60	SDG3	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-75	SDG3	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-85	SDG3	null	1	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-90	SDG3	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-24	SDG12	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-32	SDG12	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-50	SDG12	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-77	SDG12	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-87	SDG12	null	1	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-92	SDG12	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-21	SDG14	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-23	SDG14	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-39	SDG14	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-42	SDG14	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-70	SDG14	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-85	SDG14	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-93	SDG14	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-14	SDG3	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-22	SDG3	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-29	SDG3	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-31	SDG3	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-34	SDG3	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-35	SDG3	null	1	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-37	SDG3	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-21	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-23	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-30	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-38	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-39	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-42	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-75	SDG7	null	1	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-93	SDG7	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-23	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-30	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-42	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-60	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-62	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-69	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-84	SDG15	null	1	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-85	SDG15	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-23	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-38	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-42	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-60	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-62	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-69	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-75	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-84	SDG16	null	1	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-90	SDG16	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-15	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-45	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-46	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-47	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-52	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-63	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-74	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-78	SDG15	null	1	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-86	SDG15	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-23	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-30	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-38	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-39	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-42	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-75	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-84	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-85	SDG6	null	1	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-93	SDG6	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-23	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-30	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-33	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-38	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-42	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-66	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-85	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-90	SDG8	null	1	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-94	SDG8	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-18	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-24	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-32	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-50	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-54	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-64	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-87	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-89	SDG16	null	1	null
Qhalshs01929774	Organizing autonomy in the workplace Digitalization, a liberated enterprise, a rejection by the millenials of the burdens of the traditional enterprise, agile mode: many theses invite us to think that private or public structures must change their work organization to conform to what is predicted for tomorrow's work: more autonomy left to workers, more opportunities to test ideas, to participate in their realization, more responsiveness, more exchanges and collaboration. While these ideas are very much in vogue in companies, the book questions them from the point of view of organizational needs, which, while freezing work in processes, nonetheless return regularly when it comes to being able to produce or provide services on a large scale. From the point of view of work activity, too, autonomy is expected from the organization. The book opens a discussion on the place to be given to organization in tomorrow's work. Digitalization , Autonomy , Agile , Collaborative , Work , Work organization .  	L-92	SDG16	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-14	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-20	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-22	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-29	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-34	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-35	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-37	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-38	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-41	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-42	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-14	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-20	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-22	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-29	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-31	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-34	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-37	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-38	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-41	SDG7	null	1	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-42	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-6	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-14	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-20	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-29	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-31	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-34	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-37	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-38	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-40	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-41	SDG7	null	1	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-42	SDG7	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-14	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-20	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-22	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-29	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-31	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-34	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-35	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-37	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-38	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-41	SDG6	null	1	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-42	SDG6	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-14	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-20	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-23	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-29	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-31	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-32	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-34	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-35	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-37	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-38	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-41	SDG7	null	1	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-42	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-12	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-14	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-20	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-22	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-29	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-31	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-32	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-34	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-37	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-38	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-41	SDG7	null	1	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-42	SDG7	null	1	null
Q02halshs01599558	Performance and Inequality in Health: A Comparison of Child and Maternal Health across Asia A country's performance in health attainment refers to both its achievement (level) and its improvement (evolution) in the health domain. Studies on performance generally measure health attainment using the average health level of the population, and quantify health improvement employing the change in attainment over time. However this approach is flawed because the change in attainment does not satisfy good properties, on the one hand, and because health attainment should not only account for the average health level, but also for disparities in health in the population, on the other hand. We propose a solution to the first limitation by following the lead of Kakwani (1993), who uses achievement and improvement measures which are based on attainment measures and which satisfy important properties. For the second limitation, we extend the work of Kakwani and propose new definitions of attainment that account for the average health level but also for health inequalities in the population. Specifically, we focus on overall and social health inequalities and on the health of the poor. By including these new attainment variables into Kakwani's indices, we generate new classes of achievement and improvement indices. Using data on 11 low and middle-income Asian countries in the twenty-first century, we highlight that child and maternal health have generally improved in recent decades, due to both an increase in the average health level and a decrease in inequalities.  	L-47	SDG1	1	null	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-15	SDG2	1	null	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-15	SDG7	1	null	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-15	SDG12	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-88	SDG12	1	null	null
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-48	SDG1	1	null	null
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-48	SDG5	1	null	null
Q13hal02149635	Social investment: what strategy for France? This book brings together the main elements presented and discussed during the series of seminars Social Investment: What Strategy for France? , organized between January 2016 and January 2017 by the Apprentis d'Auteuil, the Caisse nationale des Allocations familiales (Cnaf), the Direction générale de la cohésion sociale (DGCS), France Stratégie and the Laboratoire interdisciplinaire d'évaluation des politiques publiques of Sciences Po Paris. Two main objectives guided these seminars. The first was to clarify the concept of social investment in order to better grasp its content and its usefulness for action. The second was to clarify the operational challenges of social investment as it relates to France. These dimensions were explored in seven sessions: ~ a launching session drew a comparison between countries and dealt with the general issues of definition and evaluation; ~ five thematic sessions dealt with public policies in the field of social investment: five thematic sessions dealt with public policies in the areas of: early childhood care conditions; family/work life articulation and gender equality; youth policies; new forms of poverty alleviation; lifelong learning and comprehensive support to and in employment; ~ a concluding session enabled a wide range of actors in the social field to position themselves in relation to the social investment strategy. The organization of the book is based on the content of these seven sessions. The introduction presents the main cross-cutting lessons of the seminar. All the contributions, presentations and detailed summaries of these seminars can be found on the website: http://www.investissementsocial.org.  	L-65	SDG16	1	null	null
Q13halshs01379288	Employee representatives Employee representatives, elected to the works council or the CHSCT, trade union delegates... France has more than half a million employee representatives. While it is easy to point to a lack of social dialogue in this country, the lack of studies devoted to its main players is surprising. What do we know about the motivations, the work carried out to inform and defend other employees, or the career development of employee representatives? How are they perceived by their colleagues and employers? Are they discriminated against? Based on very rich but rarely used statistical sources, this book provides for the first time an overview of the activity of employee representatives. It shows that the legal framework in which they operate is unsuitable and too often tends to set representatives, employees and employers against each other, and proposes solutions to ensure that employees' interests are better represented, without fear, during negotiations and in the daily life of companies. Employee delegate .  	L-25	SDG8	1	null	null
Q15hal02156136	Towards effective ecosystem services assessment in marine and coastal management Despite facing increasing pressures and natural threats, complex marine and coastal ecosystems provide a large diversity of services which directly and indirectly contribute to our wellbeing. Assessing the socioeconomic importance of these ecosystem services has been increasingly recognised as a potential argument to support sustainable management of marine ecosystems. A diversity of qualitative and quantitative methodologies and tools has been used including monetary and non-monetary approaches. One way of scoping and simplifying assessments is to start with a clear focus on the management questions that could benefit from a better understanding of ecosystem services. Such a demand-driven approach requires an ecosystem service assessment that begins with the stakeholders. Expert scientific knowledge can be used to identify what data and types of assessment are actually needed to inform management decisions, and also what, practically, can be undertaken in terms of assessment. This chapter presents a stepwise process, called the ‘triage,’ that creates a transparent and strategic process engaging practitioners to determine where best to focus the effort of both natural and social scientists involved in a marine and coastal ecosystem services assessment. Pressures , Natural threats , Marine ecosystems , Coastal ecosystems , Services , Wellbeing , Socioeconomic , Ecosystem services , Sustainable management , Qualitative methodologies , Quantitative methodologies , Monetary and non-monetary approaches , Ecosystem service assessment , Stakeholders , Expert scientific , Triage  	L-64	SDG8	1	null	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-93	SDG10	1	null	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-93	SDG11	1	null	null
Q167	The space of discourse. Media and planning conflicts in London Documents that allow us to measure protest activity, but press sources need to be critically questioned because of the specificities that structure the production of media information. On the occasion of a work carried out in London on opposition to urban renewal policies since the end of the 1990s, we show how these sources have been used to identify the extent of protest. In doing so, we bring to light certain framing effects in the local press, particularly geographical ones, which participate in defining the contours of regeneration as a public problem. Governance; Media; Planning conflict; Urban regeneration governance approach; mass media; media role; popular protest; urban policy; urban renewal; England; London [England]; United Kingdom  	L-45	SDG11	1	null	null
Q692	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Multi-usage hydropower single dam management: chance-constrained optimization and stochastic viability We consider the management of a single hydroelectric dam, subject to uncertain inflows and electricity prices and to a so-called “tourism constraint”: the water storage level must be high enough during the tourist season with high enough probability. We cast the problem in the stochastic optimal control framework: we search at each time t the optimal control as a function of the available information at t. We lay out two approaches. First, we formulate a chance-constrained stochastic optimal control problem: we maximize the expected gain while guaranteeing a minimum storage level with a minimal prescribed probability level. Dualizing the chance constraint by a multiplier, we propose an iterative algorithm alternating additive dynamic programming and update of the multiplier value “à la Uzawa”. Our numerical results reveal that the random gain is very dispersed around its expected value; in particular, low gain values have a relatively high probability to materialize. This is why, to put emphasis on these low values, we outline a second approach. We propose a so-called stochastic viability approach that focuses on jointly guaranteeing a minimum gain and a minimum storage level during the tourist season. We solve the corresponding problem by multiplicative dynamic programming. To conclude, we discuss and compare the two approaches. 2015, Springer-Verlag Berlin Heidelberg. Chance constraints; Dynamic programming; Energy management; Hydroelectric dam management; Stochastic optimal control; Stochastic viability Constrained optimization; Energy management; Hydroelectric power plants; Iterative methods; Optimal control systems; Probability; Problem solving; Stochastic control systems; Stochastic systems; Chance constraint; Chance-constrained optimizations; Iterative algorithm; Prescribed probability; Stochastic optimal control; Stochastic optimal control problem; Stochastic viability; Water storage levels; Dynamic programming  	C-26	SDG7	1	null	null
Q0523	Three-dimensional modeling of the mixing state of particles over Greater Paris SCRAM simulates the particle mixing state and solves the aerosol dynamic evolution taking into account the processes of coagulation, condensation/evaporation, and nucleation. Both the size and mass fractions of chemical components of particles are discretized. The performance of SCRAM to model air quality over Greater Paris is evaluated by comparison to PM2.5, PM10, and Aerosol Optical Depth (AOD) measurements. Because air quality models usually assume that particles are internally mixed, the impact of the mixing state on aerosols formation, composition, optical properties, and their ability to be activated as cloud condensation nuclei (CCN) is investigated. The simulation results show that more than half (up to 80% during rush hours) of black carbon particles are barely mixed at the urban site of Paris, while they are more mixed with organic species at a rural site. The comparisons between the internal-mixing simulation and the mixing state-resolved simulation show that the internal-mixing assumption leads to lower nitrate and higher ammonium concentrations in the particulate phase. Moreover, the internal-mixing assumption leads to lower single scattering albedo, and the difference of aerosol optical depth caused by the mixing state assumption can be as high as 72.5%. Furthermore, the internal-mixing assumption leads to lower CCN activation percentage at low supersaturation, but higher CCN activation percentage at high supersaturation. 2016. American Geophysical Union. All Rights Reserved. aerosol; aerosol composition; aerosol formation; air quality; atmospheric modeling; atmospheric pollution; black carbon; chemical property; cloud condensation nucleus; particle size; particulate matter; supersaturation; urban site; France; Ile de France; Paris; Ville de Paris; Polyphemus  	L-15	SDG15	1	null	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-93	SDG9	1	null	null
Q2169	Setting inventory levels in a bike sharing network Bike sharing systems (BSSs) allow customers to rent bicycles at automatic rental stations distributed throughout a city, use them for a short period of time, and return them to any station. One of the major issues that BSS operators must address is nonhomogeneous asymmetric demand processes. These demand processes create an inherent imbalance, thus leading to shortages either of bicycles when users are attempting to rent them and of vacant lockers when users are attempting to return them. The predominant approach taken by operators to cope with this difficulty is to reposition bicycles to rebalance the inventory levels at the different stations. Most repositioning studies assume that a target inventory level or range of inventory levels is known for each station. In this paper, we focus on determining the correct target level for repositioning according to a well-defined objective. This is a challenging task because of the nature of the user behavior that creates the interactions among the inventory levels at different stations. For example, if bicycles are not available at the user’s origin, the user may abandon the system, use other means of transportation, or look for available bicycles at a neighboring station. If, in another case, a locker is not available at a user’s destination, then that user is obliged to find a station with available space to return the bicycle to the system. Thus, an empty/full station can create a spillover of demand to nearby stations. In addition, stations are related by origin–destination pairing. In this paper, we take this effect into consideration for the first time when setting target inventory levels and develop a robust guided local search algorithm for that purpose. We show that neglecting the interactions among stations leads to inferior decision making. Copyright 2017 INFORMS. Bike sharing systems; Inventory management; Simulation Behavioral research; Decision making; Inventory control; Locks (fasteners); Sporting goods; Time sharing systems; Asymmetric demands; Guided local search algorithms; Inventory levels; Inventory management; Means of transportations; Non-homogeneous; Sharing systems; Simulation; Bicycles  	C-26	SDG11	1	null	null
Q2232	National survey of telemedicine education and training in medical schools in France Introduction: Telemedicine is a remote medical practice using information communication technology (ICT), and has been increasing in France since 2009. With all new forms of medical practice, education and training (ET) is required for quality and safety. To date, implementation of telemedicine ET has not been assessed in France. The objective of this study was to describe the implementation of telemedicine ET and evaluate the knowledge, attitudes and practices (KAP) of deans and associate deans from all medical schools in France. Methods: A cross-sectional non-mandatory, descriptive online survey with a self-administered questionnaire was performed from 15 November to 6 December, 2017. Respondents were accessed through the ‘Conférence des doyens des Facultés de médecine’. Results: There were 48 respondents with a 47.4% response rate among deans. Telemedicine ET was limited in France; 10.4% in 1st year medicine (PACES); 4% in the final 3 years of medical school (D.F.A.S.M.) and 18.8% in medical residency. Emergency medicine, dermatology, radiology, neurology and geriatrics were specialties with implemented telemedicine training during residency. Of all respondents, 90% expressed a need to increase telemedicine ET, among which 75% accepted external support. A highly positive attitude towards telemedicine practice was reflected by 60.4% of respondents, and 56.2% practiced telemedicine at least once. Discussion: This study was the first to assess national telemedicine ET implementation in France. Telemedicine was integrated into initial medical education; however, telemedicine ET remains limited despite the positive attitudes of deans and associate deans. Further research would need to be conducted on telemedicine ET implementation and KAP of medical students and residents. The Author(s) 2019. curriculum; medical education; medical school; residency training; Telemedicine adult; article; clinical article; curriculum; dermatology; emergency medicine; female; France; geriatrics; human; human experiment; male; medical school; medical student; neurology; questionnaire; radiology; residency education; telemedicine; attitude  	L-15	SDG3	1	null	null
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-65	SDG11	1	null	null
Q2308	Impact of microbial activity on the mobility of metallic elements (Fe, Al and Hg) in tropical soils Dissolved organic carbon (DOC), especially low molecular mass organic acids (LMMOAs) derives principally from biota degradation process in which soil microorganisms are the main actors and from roots exudates. The presence of LMMOAs led to an increase of availability and mobility of metallic elements through the formation of organo-metallic complex. In tropical soils, very few information about LMMOAs quantification and their role in the biogeochemical process related to trace metals cycling was available. Quantification of LMMOAs is limited due to their low concentration and rapid degradation. Until now, the role of microbial activity as well as LMMOAs in the biogeochemical cycle of metallic elements in tropical soils has not been investigated. The present study was conducted to evaluate the effect of microbial activity and biomass on the availability and mobility of metallic elements (Fe, Al and Hg) in two tropical soils, Ferralsol and Acrisol. We also quantified LMMOAs contents in soil solutions and addressed to their role in the mobilization of metals. Utilization of Diffuse Gradient in Thin film (DGT) method permits to analyze bioavailable metal in both fractions: organically complexed and free metals. The results show that the quantity of Fe, Al and Hg labile were higher in Ferralsol than Acrisol soils. This was more accentuated for the 50 cm-depth of soils where the microbial activities and the organic carbon content were important. Concentration of LMMOAs of Ferralsol and Acrisol were lower in compare to coniferous and deciduous forest soils. Proportions of LMMOAs in DOC were very small at 10.5% and 6.85% in the Ferralsol and Acrisol soils, respectively. The mobilization of Fe, Al and Hg in Ferralsol and Acrisol soils appeared to vary depending on the soil physico-chemical characteristics (sorption capacities and metals content) and also on the microbial biomass and activity. Soil pH influences the acidity of the functional groups in organic molecules and consequently their speciation. In addition, low pH increase proton competition within acidic functional groups involved in coordinate bond. The content of CEC in Ferralsol is higher than Acrisol that is related to the high contents of clay and organic carbon. Low CEC content can result in a decrease of retain of the cationic trace metals. Low CEC content led to a decrease of the capacity of retaining of metallic elements in tropical soils in compare to temperate soils. 2018 DGT; DOC; Low molecular mass organic acids; Metals; Microbial activity; Tropical soils Aluminum; Biodegradation; Biogeochemistry; Mercury (metal); Metals; Molecular mass; Organic acids; Organic carbon; Soil moisture; Trace elements; Tropics; Acidic functional groups; Dissolved organic carbon; Low molecular mass organic acids; Microbial activities; Organic carbon contents; Organo-metallic complexes; Physicochemical characteristics; Tropical soils; Soil pollution; acidity; Acrisol; biogeochemical cycle; biomass; cation exchange capacity; clay soil; deciduous forest; dissolved organic carbon; Ferralsol; forest soil; microbial activity; mobilization; organic acid; pH; soil degradation; soil microorganism; speciation (chemistry); trace metal; tropical soil  	L-65	SDG15	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-26	SDG12	1	null	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-15	SDG8	1	null	null
Q04889	Intermittent large amplitude internal waves observed in Port Susan, Puget Sound A previously unreported internal tidal bore, which evolves into solitary internal wave packets, was observed in Port Susan, Puget Sound, and the timing, speed, and amplitude of the waves were measured by CTD and visual observation. Acoustic Doppler current profiler (ADCP) measurements were attempted, but unsuccessful. The waves appear to be generated with the ebb flow along the tidal flats of the Stillaguamish River, and the speed and width of the resulting waves can be predicted from second-order KdV theory. Their eventual dissipation may contribute significantly to surface mixing locally, particularly in comparison with the local dissipation due to the tides. Visually the waves appear in fair weather as a strong foam front, which is less visible the farther they propagate. 2017 Elsevier Ltd Coastal waters; Internal waves; Korteweg-de Vries equation; Mixing processes; Tidal effects Acoustic Doppler Current Profiler; coastal water; comparative study; equation; internal wave; intertidal environment; mixing; reaction kinetics; tidal flat; Puget Sound; Stillaguamish River; United States; Washington [United States]  	L-65	SDG14	1	null	null
Q08106	Stakeholder engagement and biodiversity conservation challenges in social-ecological systems: some insights from biosphere reserves in western Africa and France Biosphere reserves are an example of social-ecological systems that combine biodiversity conservation and socioeconomic development with knowledge generation and dissemination (both scientific and local). We review lessons learned from case studies biosphere reserves in western African and France, highlighting the importance of early stakeholder engagement to build knowledge for achieving sustainable development. We discuss the evolution of the concept of biosphere reserves and its application over time in different socioeconomic and cultural settings. The diversity of stakeholders and their different needs and perceptions about nature conservation complicate implementation processes, sometimes resulting in conflicts about the objectives and zonation of biosphere reserves. Dialogue among the different stakeholders must start at an early planning phase and be based on the principle of social and ecological solidarity. Dialogue must then be pursued, formalized, ritualized, and translated both in terms of biosphere reserve management and in terms of political support. Tools and methods exist that can facilitate such dialogue and colearning. 2016 by the author(s). Biosphere reserves; Learning; Social-ecological systems; Solidarity; Sustainable development biodiversity; biosphere; conservation management; learning; nature conservation; stakeholder; sustainable development; France; West Africa  	L-88	SDG8	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-87	SDG11	1	null	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-71	SDG10	1	null	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-88	SDG3	1	null	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-24	SDG9	1	null	null
Q041217	Detour and break optimising distance, a new perspective on transport and urbanism By studying the mathematical properties of metrics, we identify three fundamental characteristics of distance, which are optimality, detour and break. In this paper, we explore the implications of these properties for transport planning, urbanism and spatial planning. We state that distances contain the idea of optimum and that any distance is associated to a search for optimisation. Pedestrian movements obey this principle and sometimes depart from designed routes. Local suboptimality conveyed by public transport maps has to be corrected by interventions on public space to relieve the load on central parts of networks. The second principle we state is that detour in distances is most often a means to optimise movement. Fast transport systems generate most of the detour observed in geographical spaces at regional scale. This is why detour has to be taken into account in regional transport policies. The third statement is that breaks in movement contribute to optimising distances. Benches, cafés, pieces of art, railway stations are examples of the urban break. These facilities of break represent an urban paradox: they organise the possibility of a break, of a waste of time in a trip, and they also contribute to optimising distances in a wider network. In that sense, break should be considered as a relevant principle for the design of urban space in order to support a pedestrian-oriented urban form. The Author(s) 2016. Network structure; Pedestrian movement; Spatial planning; Transport networks; Urban design optimization; pedestrian; public space; public transport; spatial planning; transportation planning; transportation policy; transportation system; urban design; urbanization  	L-64	SDG1	1	null	null
Q052942	Fair retirement under risky lifetime A premature death unexpectedly brings a life and a career to their end, leading to substantial welfare losses. We study the retirement decision in an economy with risky lifetime and compare the laissez-faire with egalitarian social optima. We consider two social objectives: (1) the maximin on expected lifetime welfare, allowing for a compensation for unequal life expectancies, and (2) the maximin on realized lifetime welfare, allowing for a compensation for unequal lifetimes. The latter optimum involves, in general, decreasing lifetime consumption profiles as well as raising the retirement age. This result is robust to the introduction of unequal life expectancies and unequal productivities. 2016 by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association. SOCIAL-SECURITY; INCOME; AGE; MORTALITY  	L-15	SDG3	1	null	null
Q092655	Persistent fossil fuel growth threatens the Paris Agreement and planetary health Persistent fossil fuel growth threatens the Paris Agreement and planetary health Amidst declarations of planetary emergency and reports that the window for limiting climate change to 1.5 °C is rapidly closing, global average temperatures and fossil fuel emissions continue to rise. Global fossil CO2 emissions have grown three years consecutively: +1.5% in 2017, +2.1% in 2018, and our slower central projection of +0.6% in 2019 (range of -0.32% to 1.5%) to 37 ± 2 Gt CO2 (Friedlingstein et al 2019 Earth Syst. Sci. Data accepted), after a temporary growth hiatus from 2014 to 2016. Economic indicators and trends in global natural gas and oil use suggest a further rise in emissions in 2020 is likely. CO2 emissions are decreasing slowly in many industrialized regions, including the European Union (preliminary estimate of -1.7% [-3.4% to +0.1%] for 2019, -0.8%/yr for 2003-2018) and United States (-1.7% [-3.7% to +0.3%] in 2019, -0.8%/yr for 2003-2018), while emissions continue growing in India (+1.8% [+0.7% to 3.7%] in 2019, +5.1%/yr for 2003-2018), China (+2.6% [+0.7% to 4.4%] in 2019, +0.4%/yr for 2003-2018), and rest of the world ((+0.5% [-0.8% to 1.8%] in 2019, +1.4%/yr for 2003-2018). Two under-appreciated trends suggest continued long-term growth in both oil and natural gas use is likely. Because per capita oil consumption in the US and Europe remains 5- to 20-fold higher than in China and India, increasing vehicle ownership and air travel in Asia are poised to increase global CO2 emissions from oil over the next decade or more. Liquified natural gas exports from Australia and the United States are surging, lowering natural gas prices in Asia and increasing global access to this fossil resource. To counterbalance increasing emissions, we need accelerated energy efficiency improvements and reduced consumption, rapid deployment of electric vehicles, carbon capture and storage technologies, and a decarbonized electricity grid, with new renewable capacities replacing fossil fuels, not supplementing them. Stronger global commitments and carbon pricing would help implement such policies at scale and in time. 2019 The Author(s). Published by IOP Publishing Ltd. Carbon capture; Carbon dioxide; Climate change; Costs; Digital storage; Economics; Emission control; Energy efficiency; Fuel storage; Gas emissions; Liquefied natural gas; Natural gas deposits; Vehicle-to-grid; Capture and storage technologies; Economic indicators; Energy efficiency improvements; Fossil fuel emissions; Liquified natural gas; Natural gas price; Oil and natural gas; Renewable capacity; Fossil fuels; carbon emission; carbon sequestration; climate change; emission control; energy efficiency; environmental economics; environmental indicator; European Union; fossil fuel; international agreement; liquefied natural gas; persistence; pricing policy; trend analysis; Asia; Australia; China; Europe; India; United States  	L-10	SDG3	1	null	null
Q132468	Assessment of CORDEX simulations over South America: added value on seasonal climatology and resolution considerations A new set of CORDEX simulations over South America, together with their coarser-resolution driving Global Climate Models (GCMs) are used to investigate added value of Regional Climate Models (RCMs) in reproducing mean climate conditions over the continent. There are two types of simulations with different lateral boundary conditions: five hindcast simulations use re-analysis as boundary conditions, and five other historical simulations use GCMs outputs. Multi-model ensemble means and individual simulations are evaluated against two or three observation-based gridded datasets for 2-m surface air temperature and total precipitation. The analysis is performed for summer and winter, over a common period from 1990 to 2004. Results indicate that added value of RCMs is dependent on driving fields, surface properties of the area, season and variable considered. A robust added value for RCMs driven by ERA-Interim is obtained in reproducing the summer climatology of surface air temperature over tropical and subtropical latitudes. Mixed results can be seen, however, for summer precipitation climatology in both hindcast and historical experiments. For winter, there is no noticeable improvement by the RCMs for the large-scale precipitation and surface air temperature climatology. To further understand the added value of RCMs, models deviations from observation are decomposed according to different terms that reflect the observational uncertainty, the representativeness error, the interpolation error, and the actual performance of the model. Regions where these errors are not negligible, such as in complex terrain regions, among others, can be identified. There is a clear need for complementary assessment to understand better the real value added by RCMs. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Added value; CORDEX; Model assessment; Seasonal climatology; South America air temperature; climate conditions; climate modeling; climatology; computer simulation; ensemble forecasting; global climate; hindcasting; model validation; precipitation assessment; regional climate; seasonal variation; South America  	L-60	SDG13	1	null	null
Q142459	Projected change in characteristics of near surface temperature inversions for southeast Australia Air pollution has significant impacts on human health. Temperature inversions, especially near surface temperature inversions, can amplify air pollution by preventing convective movements and trapping pollutants close to the ground, thus decreasing air quality and increasing health issues. This effect of temperature inversions implies that trends in their frequency, strength and duration can have important implications for air quality. In this study, we evaluate the ability of three reanalysis-driven high-resolution regional climate model (RCM) simulations to represent near surface inversions at 9 sounding sites in southeast Australia. Then we use outputs of 12 historical and future RCM simulations (each with three time periods: 1990–2009, 2020–2039, and 2060–2079) from the NSW/ACT (New South Wales/Australian Capital Territory) Regional Climate Modelling (NARCliM) project to investigate changes in near surface temperature inversions. The results show that there is a substantial increase in the strength of near surface temperature inversions over southeast Australia which suggests that future inversions may intensify poor air quality events. Near surface inversions and their future changes have clear seasonal and diurnal variations. The largest differences between simulations are associated with the driving GCMs, suggesting that the large-scale circulation plays a dominant role in near surface inversion strengths. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Ensemble mean; NARCliM; Near surface inversion; Temperature inversion air quality; atmospheric pollution; climate modeling; ensemble forecasting; regional climate; surface temperature; temperature effect; temperature inversion; Australia  	L-15	SDG13	1	null	null
Q142577	Future evolution of Marine Heatwaves in the Mediterranean Sea Extreme ocean warming events, known as marine heatwaves (MHWs), have been observed to perturb significantly marine ecosystems and fisheries around the world. Here, we propose a detection method for long-lasting and large-scale summer MHWs, using a local, climatological 99th percentile threshold, based on present-climate (1976–2005) daily SST. To assess their future evolution in the Mediterranean Sea we use, for the first time, a dedicated ensemble of fully-coupled Regional Climate System Models from the Med-CORDEX initiative and a multi-scenario approach. The models appear to simulate well MHW properties during historical period, despite biases in mean and extreme SST. In response to increasing greenhouse gas forcing, the events become stronger and more intense under RCP4.5 and RCP8.5 than RCP2.6. By 2100 and under RCP8.5, simulations project at least one long-lasting MHW every year, up to three months longer, about 4 times more intense and 42 times more severe than present-day events. They are expected to occur from June-October and to affect at peak the entire basin. Their evolution is found to occur mainly due to an increase in the mean SST, but increased daily SST variability also plays a noticeable role. Until the mid-21st century, MHW characteristics rise independently of the choice of the emission scenario, the influence of which becomes more evident by the end of the period. Further analysis reveals different climate change responses in certain configurations, more likely linked to their driving global climate model rather than to the individual model biases. 2019, The Author(s). Climate change; Climate simulations; Coupled regional climate models; Extreme ocean temperatures; Future scenario; Marine Heatwaves; Med-CORDEX; Mediterranean Sea climate change; climate forcing; climate modeling; computer simulation; future prospect; greenhouse gas; heat wave; marine atmosphere; numerical model; regional climate; Mediterranean Sea  	L-15	SDG2	1	null	null
Qhalshs01513690	For a treaty for the democratization of Europe How can we contain the wave of populism that risks sweeping away our democracies? How to prevent the break-up of the European Union? To put an end to disqualified economic policies, to put austerity in the minority and to fight against inequalities, it is urgent to democratize the government of the euro zone. Drafted by a multidisciplinary team of jurists, politicians and economists and taken up by Benoît Hamon, the draft treaty, presented and commented on here, establishes a Eurozone Parliamentary Assembly to promote fiscal and social justice. The treaty can be adopted as it stands by the countries that join it. The text is preceded by an introduction which explains its implementation in an educational manner. The objective is that each citizen should take ownership of the European debate and that the various social and political forces should contribute to improving this project and helping us to get out of the prevailing gloom. Europe .  	L-15	SDG10	1	null	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-15	SDG11	1	null	null
Q07hal01390558	Socio-economic impacts of co-firing in Vietnam: The case of Ninh Binh Coal Power Plant Co-firing biomass with coal is a relatively low-cost technology to utilize biomass for electricity production compared to dedicated biomass power plant. Co-firing could help to reduce the negative impact of coal power plants to economy, environment and society. Vietnam has potential to develop co-firing base on the abundant of biomass resources and because Vietnam will continue to build more coal-fired power plant in the next 2 decades as stated in the latest National Power Development Plan. Among the co-firing technologies, direct co-firing is the most suitable for Vietnam context. Despite of low biomass ratio, direct co-firing offers low investment cost and could utilize most of the biomass feedstock. Vietnam has huge biomass potential, especially the agriculture and forestry residues. These biomasses should be considered first as feedstock for co-firing. Biomass pellets is also a good choice in term of technical features and local supply. However, the price of pellets is not yet competitive with coal or agricultural residues. Economic benefit of co-firing would be higher in the plants that has following features: assess to stable biomass supply, biomass price competitive with coal, incentives and support in term of market for renewable energy utilization and waste reduction. Vietnam should start experimenting co-firing in the coal power plants that located in the area where biomass resource is available, easy to collect and deliver to the plant, using imported coal such as Vinh Tan 2, Duyen Hai 1, Long Phuoc 1…; or the plants that are soon or already depreciated such as Ninh Binh, Uong Bi or Pha Lai to utilize the existing infrastructures. The case study of co-firing 5% rice straw with coal in Ninh Binh Coal Power Plant shows that co-firing could bring benefit to the plant owner in the condition that lack supporting mechanism for co-firing as well as with the absent of carbon credit. Farmers and workers that work in biomass supply chain also benefit from co-firing, especially farmers. In addition, co-firing provide significant positive externalities, in which the most notable is health benefit from reducing air-borne pollutants. Greenhouse gas emissions reduction adds a small part to the overall benefit of co-firing. Co-firing , Vietnam , Straw  	L-46	SDG11	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-38	SDG8	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-88	SDG8	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-78	SDG5	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-78	SDG11	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-86	SDG5	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-86	SDG11	1	null	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-87	SDG11	1	null	null
Q92	Distributive effects of increasing block tariffs. the case of a mid-size city in France Consumer NGOs, local elected representatives and the media in France have recently favoured the idea of a water tariff that would be both incentive to conserve and social. Based on the evolution of the potable water share of the tariff in one of the first cities which adopted such a tariff, we calculated the distributive effect of successive changes on 9 types of housing units: single family, and condominiums of 10 and 100 apartments, where households would consume 75, 100, and 120 m3/yr. After some evolutions, the results show that all households benefit from a slight water bill reduction, and the bill is identical for the 3 housing types for the same consumption. This slight reduction leads to hypothesize that the new tariff might not be justified. A detailed analysis raises several critical observations going against a simplistic vision of progressive tariffs. But the tariff also results in large increases for large consumers, some of whom consider exiting the service and drilling their own well... This type of analysis should be done before any tariff change, given the complexity of factors involved in water bills. ASTEE 2016. Before-after comparison; Distributive effetcts; Incentive tariff; Single family/multifamily housing capital city; comparative study; complexity; drinking water; family structure; fuel consumption; household expenditure; incentive; nongovernmental organization; tariff structure; France  	L-92	SDG11	1	null	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-88	SDG11	1	null	null
Q1235	On passenger repositioning along station platform during train waiting The variability in passengers' waiting times in urban mass transit is significant at the trip level since it ranges from some dozen seconds to half headway. Despite the attention paid so far to individual wait times in urban transit systems, a related issue seemed to remain unexplored: the re-use of wait time for passenger repositioning along the boarding platform. The paper is focused on passenger wait time on urban railway platforms and its re-use for longitudinal repositioning on the boarding platform in order to save on walking time at the egress station. Building upon our stochastic model of passenger's individual journey time between access and egress stations, we refine the representation of the on-platform phases and their potential coupling, since a passenger's relocation along the access platform influences the egress situation. In the new model, the stochastic features pertain to (i) the distribution of walking speed among passengers, (ii) the distribution of repositioning distance in relation to that of the residual time between passenger arrival and train departure at the station of passenger boarding, (iii) the distribution of in-station distances between the station access/egress points and the platform. Analytical properties are obtained, including the Probability Density Function of Tap-In, Tap-Out time pairs. It is shown that the analytical formulas for normal-distributed speed and shifted exponential-distributed distances in stations are tractable. This enables for maximum likelihood estimation of distribution parameters. A real case study of urban rail transit line RER A in Parisian region is addressed, yielding reasonable parameter values for heterogeneous and homogeneous scenarios. Furthermore, this study gives the possibility to capture pedestrian congestion in the stochastic model, and to differentiate 'intra-' vs. 'inter-' individual variabilities. 2017 The Authors. Published by Elsevier B.V. Platform longitudinal distance; railway platform; smartcard data; stochastic model; waiting time  	L-93	SDG11	1	null	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-15	SDG13	1	null	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-15	SDG14	1	null	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-86	SDG13	1	null	null
Q1420	Stochastic parameterization identification using ensemble Kalman filtering combined with maximum likelihood methods  For modelling geophysical systems, large-scale processes are described through a set of coarse-grained dynamical equations while small-scale processes are represented via parameterizations. This work proposes a method for identifying the best possible stochastic parameterization from noisy data. State-of-the-art sequential estimation methods such as Kalman and particle filters do not achieve this goal successfully because both suffer from the collapse of the posterior distribution of the parameters. To overcome this intrinsic limitation, we propose two statistical learning methods. They are based on the combination of the ensemble Kalman filter (EnKF) with either the expectation–maximization (EM) or the Newton–Raphson (NR) used to maximize a likelihood associated to the parameters to be estimated. The EM and NR are applied primarily in the statistics and machine learning communities and are brought here in the context of data assimilation for the geosciences. The methods are derived using a Bayesian approach for a hidden Markov model and they are applied to infer deterministic and stochastic physical parameters from noisy observations in coarse-grained dynamical models. Numerical experiments are conducted using the Lorenz-96 dynamical system with one and two scales as a proof of concept. The imperfect coarse-grained model is modelled through a one-scale Lorenz-96 system in which a stochastic parameterization is incorporated to represent the small-scale dynamics. The algorithms are able to identify the optimal stochastic parameterization with good accuracy under moderate observational noise. The proposed EnKF-EM and EnKF-NR are promising efficient statistical learning methods for developing stochastic parameterizations in high-dimensional geophysical models. 2018, 2018 The Author(s). Publisehd by Informa UK Limited, trading as Taylor & Francis Group. expectation–maximization algorithm; model error estimation; parameter estimation; stochastic parameterization algorithm; data assimilation; ensemble forecasting; Kalman filter; numerical model; parameterization; stochasticity  	L-86	SDG14	1	null	null
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-14	SDG7	1	null	null
Q1442	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic decomposition applied to large-scale hydro valleys management We are interested in optimally controlling a discrete time dynamical system that can be influenced by exogenous uncertainties. This is generally called a Stochastic Optimal Control (SOC) problem and the Dynamic Programming (DP) principle is one of the standard ways of solving it. Unfortunately, DP faces the so-called curse of dimensionality: the complexity of solving DP equations grows exponentially with the dimension of the variable that is sufficient to take optimal decisions (the so-called state variable). For a large class of SOC problems, which includes important practical applications in energy management, we propose an original way of obtaining near optimal controls. The algorithm we introduce is based on Lagrangian relaxation, of which the application to decomposition is well-known in the deterministic framework. However, its application to such closed-loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed. The resulting methodology is called Dual Approximate Dynamic Programming (DADP). We briefly present DADP, give interpretations and enlighten the error induced by the approximation. The paper is mainly devoted to applying DADP to the management of large hydro valleys. The modeling of such systems is presented, as well as the practical implementation of the methodology. Numerical results are provided on several valleys, and we compare our approach with the state of the art SDDP method. 2018 Elsevier B.V. Decomposition methods; Discrete time stochastic optimal control; Dynamic programming; Energy management; Stochastic Programming Dynamical systems; Energy management; Landforms; Numerical methods; Stochastic control systems; Stochastic models; Stochastic programming; Stochastic systems; Approximate dynamic programming; Curse of dimensionality; Decomposition methods; Discrete-time dynamical systems; LaGrangian relaxation; Statistical approximation; Stochastic decomposition; Stochastic optimal control; Dynamic programming  	C-26	SDG7	1	null	null
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-23	SDG11	1	null	null
Q1444	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? The multiple vehicle balancing problem This paper deals with the multiple vehicle balancing problem (MVBP). Given a fleet of vehicles of limited capacity, a set of vertices with initial and target inventory levels and a distribution network, the MVBP requires to design a set of routes along with pickup and delivery operations such that inventory is redistributed among the vertices without exceeding capacities, and routing costs are minimized. The MVBP is NP-hard, generalizing several problems in transportation, and arising in bike-sharing systems. Using theoretical properties of the problem, we propose an integer linear programming formulation and introduce strengthening valid inequalities. Lower bounds are computed by column generation embedding an ad-hoc pricing algorithm, while upper bounds are obtained by a memetic algorithm that separate routing from pickup and delivery operations. We combine these bounding routines in both exact and matheuristic algorithms, obtaining proven optimal solutions for MVBP instances with up to 25 stations. 2018 Wiley Periodicals, Inc. bicycle sharing system; column generation; dominance properties; memetic algorithm; valid inequalities; vehicle routing  	C-26	SDG11	1	null	null
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-14	SDG9	1	null	null
Q1468	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Infrastructure maintenance, regeneration and service quality economics: A rail example This paper proposes a formalized framework for the joint economic optimization of continuous maintenance and periodic regeneration of rail transport infrastructure taking into account output consisting not only in traffic levels but also in track service quality. In contrast with much optimization work pertaining to spatially contiguous maintenance works, its principal economic emphasis and objective focus are centered on the optimal allocation of current maintenance and periodic renewal expenses, on their yearly distribution among large network partitions, and on infrastructure pricing. The model equations are based on very simple assumptions of infrastructure degradation laws and on a manager's objective function optimized through optimal control procedures. Equations are tested on national French rail track segment databases using Box-Cox transformations and match rail regeneration and maintenance practices prevailing in France. More generally, the paper makes a broad contribution to capital theory, on the optimal maintenance and renewal of equipment, and defines a method applicable not only to other transport infrastructure but to a wide range of capital goods, including housing, cars and industrial machines. 2016 Elsevier Ltd. Box-Cox transformation; Current maintenance; Optimal pricing; Regenerative maintenance; Spatial autocorrelation; Transport infrastructure Economics; Quality of service; Railroads; Transportation; Box Cox transformation; Continuous maintenance; Economic optimization; Infrastructure maintenance; Maintenance practices; Optimal pricing; Spatial autocorrelations; Transport infrastructure; Maintenance; autocorrelation; maintenance; optimization; price dynamics; spatial analysis; transportation economics; transportation infrastructure; France  	C-26	SDG9	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-62	SDG14	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-88	SDG14	1	null	null
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-14	SDG7	1	null	null
Q2097	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stochastic Optimization of Braking Energy Storage and Ventilation in a Subway Station In the Paris subway system, stations represent about one-third of the overall energy consumption. Within stations, ventilation is among the top consuming devices; it is operated at maximum airflow all day long, for air quality reasons. In this paper, we present a concept of energy system that displays comparable air quality while consuming much less energy. The system comprises a battery that makes it possible to recover the trains braking energy, arriving under the form of erratic and strong peaks. We propose an energy management system that, at short time scale, controls energy flows and ventilation airflow. By using proper optimization algorithms, we manage to match supply with demand, while minimizing energy daily costs. For this purpose, we have designed algorithms that take into account the braking variability. They are based on the so-called stochastic dynamic programming (SDP) mathematical framework. We fairly compare SDP-based algorithms with the widespread model predictive control (MPC) ones. First, both SDP and MPC yield energy/money operating savings of the order of one-third, compared to the current management without battery. Second, depending on the specific design, we observe that SDP outperforms MPC by a few percent, with an easier online numerical implementation. 1969-2012 IEEE. energy management; Optimization methods; stochastic optimal control Air quality; Braking; Dynamic programming; Electric batteries; Energy management; Energy utilization; Mathematical models; Model predictive control; Predictive control systems; Railroads; Random processes; Solar cells; Stochastic control systems; Stochastic models; Stochastic systems; Subway stations; Subways; Ventilation; Atmospheric model; Energy management systems (EMS); Numerical implementation; Optimization method; Public transportation; Stochastic dynamic programming; Stochastic optimal control; Stochastic optimizations; Energy management systems  	C-26	SDG7	1	null	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-60	SDG6	1	null	null
Q2831	Deterioration of swelling pressure of compacted Gaomiaozi bentonite induced by heat combined with hyperalkaline conditions Compacted bentonite has been considered a suitable engineered barrier material for high-level radioactive waste (HLW) repositories for several decades. However, hyperalkaline groundwater produced by cementitious materials, combined with the heat generated by nuclear decay during the long-term storage of waste canisters, may cause the deterioration of the swelling properties of compacted bentonite. In this study, a series of swelling pressure tests and scanning electron microscopy (SEM) tests were performed on compacted Gaomiaozi (GMZ) bentonite (dry density 1.7 Mg/m3) to investigate the deterioration of the swelling pressure. Results indicated that the deterioration of the swelling pressure was facilitated by the temperature when the same concentration of NaOH solution was infiltrated, and a model of swelling pressure deterioration was developed to predict the long-term swelling pressure. Furthermore, the dissolution of montmorillonite and some silicate minerals, as well as the formation of non-expanding secondary minerals, led to transformations of the agglomeration patterns of the soil particles and structural damage to the bentonite, which controlled the long-term deterioration of the swelling pressure. Therefore, for the long-term operation of an HLW repository, the deterioration of the swelling pressure of compacted bentonite should be monitored, and safety assessments should account for the effects of heat and alkalinity. 2020 Bentonite damage; Gaomiaozi bentonite; Heat combined with hyperalkaline conditions; Microscopic test; Swelling pressure deterioration Bentonite; Groundwater; Scanning electron microscopy; Silicates; Sodium hydroxide; Soil testing; Swelling; Cementitious materials; Compacted bentonite; Engineered Barrier Materials; Gaomiaozi bentonites; High level radioactive waste repositories; Hyper-alkaline; Swelling pressures; Swelling properties; Deterioration  	L-66	SDG6	1	null	null
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-23	SDG16	1	null	null
Q3149	Trickle-Down ethnic politics: drunk and absent in the Kenya police force (1957-1970) How does ethnic politics affect the state's ability to provide policing services? Using a panel of administrative personnel data on the full careers of 6,784 police officers, we show how the rise of ethnic politics around Kenya's independence influenced policemen's behavior. We find a significant deterioration in discipline after Kenya's first multiparty election for those police officers of ethnic groups associated with the ruling party. These effects are driven by a behavioral change among these policemen. We find no evidence of favoritism within the police. Instead, our results are consistent with co-ethnic officers experiencing an emboldenment effect. Our findings highlight that the state's security apparatus, at its most granular level, is not insulated from ethnic politics. 2018 American Economic Association. PUBLIC-GOODS; DIVISIONS; DIVERSITY; AFRICA; BUREAUCRACY; ELECTION; VIOLENCE; SERVICE  	L-88	SDG16	1	null	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-15	SDG7	1	null	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-15	SDG13	1	null	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-15	SDG16	1	null	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-86	SDG7	1	null	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-86	SDG13	1	null	null
Q3345	Comparing the results of a multinomial or binary logit models between several groups based on estimated probabilities In sociology it is common to attempt to compare the effects of a variable within a given logit model conducted with several groups. The most common way of doing this consists in directly comparing the value of the coefficient of the variable in question. However, this practice raises serious methodological problems in the case of a logit model. This point was raised in the sociological literature by Allison in the late 1990s. An increasing number of studies have been dedicated to the subject since the late 2000s. Our objective here is to cover this question for a case in which the variable of interest is categorical and in a general framework combining binary and multinomial logistic mobilisations. The solutions discussed in this article consist in translating a logit coefficient in the form of probabilities. Having presented the issue at stake and the different forms of solution proposed, we study the operationalisation of two methods for the translation of this logit coefficient, experimental deviation and pure deviation, from the point of view of comparison between several groups of results within a logit model. The Author(s) 2019. Average marginal effect; experimental deviation; logit modeling; logistic regression; pure deviation COEFFICIENTS; REGRESSION; PROBIT  	L-86	SDG16	1	null	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-15	SDG10	1	null	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-15	SDG16	1	null	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-47	SDG10	1	null	null
Q03179	Les conglomérats familiaux (3) Although this is a past history, dating back to the 1990s, the conglomerates in Indonesia linked to the Suharto family are still exemplary of a problem that is still topical in terms of collective action: the importance of distinguishing between the general interest and special interests. The equation is simple in principle. Economic development and progress for all requires investment in infrastructure and other essential goods (World Bank, 1994). Since these are extraordinary operations that require a long-term collective effort, they require political will at the highest levels of government and stable institutions to achieve them. Elites must adhere to the idea that the common good is distinct from their private interests and that access to power is not the mechanism for distributing rents for their primary benefit. When these conditions are not met, collective energy dissipates, international aid evaporates and projects fail. These issues affecting the behaviour of elites must be addressed head-on. The difficulty of many emerging countries to equip themselves with essential infrastructure - technical networks, education, health - in fact masks a major lack of political commitment on the part of elites and corrupt practices. Indonesia has experienced strong growth since the 1970s; it has benefited from the unfailing support of international aid - up to 4 billion dollars a year from the United States and an equivalent amount of aid from Japan and developed countries [1]. The New York Times, Jan. 28, 2008, Suharto Dies at 86... Yet it continues to suffer from inequality, poor infrastructure and corruption. According to Transparency International, Indonesia ranks 100th out of 183 countries in terms of transparency and probity [2].  	L-47	SDG16	1	null	null
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-60	SDG10	1	null	null
Q05741	The impact of randomness on the distribution of wealth: Some economic aspects of the Wright-Fisher diffusion process In this paper we consider some elementary and fair zero-sum games of chance in order to study the impact of random effects on the wealth distribution of N interacting players. Even if an exhaustive analytical study of such games between many players may be tricky, numerical experiments highlight interesting asymptotic properties. In particular, we emphasize that randomness plays a key role in concentrating wealth in the extreme, in the hands of a single player. From a mathematical perspective, we interestingly adopt some diffusion limits for small and high-frequency transactions which are otherwise extensively used in population genetics. Finally, the impact of small tax rates on the preceding dynamics is discussed for several regulation mechanisms. We show that taxation of income is not sufficient to overcome this extreme concentration process in contrast to the uniform taxation of capital which stabilizes the economy and prevents agents from being ruined. 2017 Elsevier B.V. Fair zero-sum games; Impact of modes of taxation; Inequalities; Wealth distribution; Wright–Fisher diffusions Diffusion; Game theory; Random processes; Analytical studies; Asymptotic properties; Inequalities; Numerical experiments; Population genetics; Regulation mechanisms; Wealth distributions; Zero-sum game; Taxation  	L-88	SDG10	1	null	null
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-26	SDG11	1	null	null
Q19713	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Platoons of connected vehicles can double throughput in urban roads Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the maximum flows that the roads connecting to the intersection can carry. This capacity can be increased if vehicles cross the intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. This paper assesses the potential mobility benefits of platooning. It argues that saturation flow rates, and hence intersection capacity, can be doubled or tripled by platooning. The argument is supported by the analysis of three queuing models and by the simulation of a road network with 16 intersections and 73 links. The queuing analysis and the simulations reveal that a signalized network with fixed time control will support an increase in demand by a factor of (say) two or three if all saturation flows are increased by the same factor, with no change in the control. Furthermore, despite the increased demand vehicles will experience the same delay and travel time. The same scaling improvement is achieved when the fixed time control is replaced by the max pressure adaptive control. Part of the capacity increase can alternatively be used to reduce queue lengths and the associated queuing delay by decreasing the cycle time. Impediments to the control of connected vehicles to achieve platooning at intersections appear to be small. 2017 Elsevier Ltd Adaptive cruise control; Connected vehicles; Connected vehicles; Intersection capacity; Platooning; Saturation flow rate Adaptive cruise control; Queueing networks; Queueing theory; Roads and streets; Traffic control; Traffic signals; Transportation; Travel time; Vehicles; Adaptive Control; Capacity increase; Intersection capacity; Platooning; Potential mobility; Queuing analysis; Saturation flow rates; Vehicle technology; Cruise control; computer simulation; saturation; transport vehicle; travel time; urban area; urban transport  	C-42	SDG11	1	null	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-71	SDG16	1	null	null
Q011149	Financing the Consumption of the Young and Old in France A better understanding of the resource allocation across ages is fundamental to put in place welfare reforms in the context of population ageing. In times of major demographic change, the redistribution of resources between age groups and the funding of the economically inactive aged remains a recurring topic of public debate and a major public policy concern in OECD countries. Governments search for a policy mix that will improve thequality of life of the elderly, while at the same time investing in the future of the young and reducing the fiscal burden on the working population. Life expectancy and education requirements are increasing while budget constraints are tightening. This potentially creates tension in the allocation of resources between age groups (Preston 1984; Lee and Mason 2011a). By applying the methodology of National Transfer Accounts (NTA), this article analyzes for France (1) how the funding of consumption (publicand private) is secured at each age; (2) how the funding of consumption has changed over recent decades; and (3) how the consumption is financed compared to that of other countries (China, Germany, Japan, Sweden,United Kingdom, and United States). We consider three sources for financingconsumption: the State (net transfers and in-kind services), individuals themselves (income and assets), and families (inter vivos transfers, excluding bequests, following the NTA methodology) (United Nations 2013b). consumption behavior; elderly population; financial provision; welfare provision; young population; France  	L-80	SDG16	1	null	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-88	SDG12	1	null	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-88	SDG14	1	null	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-93	SDG12	1	null	null
Q011555	Impacts from urban water systems on receiving waters How to account for severe wet-weather events in LCA? Sewage systems are a vital part of the urban infrastructure in most cities. They provide drainage, which protects public health, prevents the flooding of property and protects the water environment around urban areas. On some occasions sewers will overflow into the water environment during heavy rain potentially causing unacceptable impacts from releases of untreated sewage into the environment. In typical Life Cycle Assessment (LCA) studies of urban wastewater systems (UWS), average dry-weather conditions are modelled while wet-weather flows from UWS, presenting a high temporal variability, are not currently accounted for. In this context, the loads from several storm events could be important contributors to the impact categories freshwater eutrophication and ecotoxicity. In this study we investigated the contributions of these wet-weather-induced discharges relative to average dry-weather conditions in the life cycle inventory for UWS. In collaboration with the Paris public sanitation service (SIAAP) and Observatory of Urban Pollutants (OPUR) program researchers, this work aimed at identifying and comparing contributing flows from the UWS in the Paris area by a selection of routine wastewater parameters and priority pollutants. This collected data is organized according to archetypal weather days during a reference year. Then, for each archetypal weather day and its associated flows to the receiving river waters (Seine), the parameters of pollutant loads (statistical distribution of concentrations and volumes) were determined. The resulting inventory flows (i.e. the potential loads from the UWS) were used as LCA input data to assess the associated impacts. This allowed investigating the relative importance of episodic wet-weather versus “continuous” dry-weather loads with a probabilistic approach to account for pollutant variability within the urban flows. The analysis at the scale of one year showed that storm events are significant contributors to the impacts of freshwater eutrophication and ecotoxicity compared to those arising from treated effluents. At the rain event scale the wet-weather contributions to these impacts are even more significant, accounting for example for up to 62% of the total impact on freshwater ecotoxicity. This also allowed investigating and discussing the ecotoxicity contribution of each class of pollutants among the broad range of inventoried substances. Finally, with such significant contributions of pollutant loads and associated impacts from wet-weather events, further research is required to better include temporally-differentiated emissions when evaluating eutrophication and ecotoxicity. This will provide a better understanding of how the performance of an UWS system affects the receiving environment for given local weather conditions. 2017 Elsevier Ltd Combined sewer overflows; Life Cycle Assessment; Stormwater; Temporal variability; Urban wastewater systems; Wet-weather emissions Effluents; Eutrophication; Life cycle; Public health; Rain; Sanitation; Sewage; Sewers; Storms; Water; Weather information services; Combined sewer overflows; Life Cycle Assessment (LCA); Stormwaters; Temporal variability; Urban wastewater system; Wet weather; River pollution; fresh water; river water; water; rain; environmental impact assessment; extreme event; life cycle analysis; performance assessment; pollution control; sanitation; sewer network; temporal variation; urban area; urban drainage; wastewater treatment; wet season; Article; ecotoxicity; effluent; eutrophication; life cycle assessment; pollutant; priority journal; sanitation; urban area; waste water; water supply; weather; analysis; city; France; sanitation; sewage; waste water; water pollutant; weather; France; Ile de France; Paris; Ville de Paris; Cities; Drainage, Sanitary; Eutrophication; Fresh Water; Paris; Rain; Sewage; Waste Water; Water Pollutants; Weather  	L-93	SDG14	1	null	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-68	SDG8	1	null	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-68	SDG16	1	null	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-80	SDG8	1	null	null
Q022221	PUBLISH AND PERISH: CREATIVE DESTRUCTION AND MACROECONOMIC THEORY A number of macroeconomic theories, very popular in the 1980s, seem to have completely disappeared and been replaced by the dynamic stochastic general equilibrium (dsge) approach. We will argue that this replacement is due to a tacit agreement on a number of assumptions, previously seen as mutually exclusive, and not due to a settlement by 'nature'. As opposed to econometrics and microeconomics and despite massive progress in the access to data and the use of statistical software, macroeconomic theory appears not to be a cumulative science so far. Observational equivalence of different models and the problem of identification of parameters of the models persist as will be highlighted by examining two examples: one in growth theory and a second in testing inflation persistence. Copyright by Fabrizio Serra editore, Pisa Roma. Controversies; Convergence; Economic growth; Identification; Inflation persistence; Macroeconomic theory  	L-80	SDG16	1	null	null
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-88	SDG4	1	null	null
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-88	SDG5	1	null	null
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-90	SDG4	1	null	null
Q022922	Teaching accreditation exams reveal grading biases favor women in male-dominated disciplines in France Discrimination against women is seen as one of the possible causes behind their underrepresentation in certain STEM (science, technology, engineering, and mathematics) subjects. We show that this is not the case for the competitive exams used to recruit almost all French secondary and postsecondary teachers and professors. Comparisons of oral non-gender-blind tests with written gender-blind tests for about 100,000 individuals observed in 11 different fields over the period 2006-2013 reveal a bias in favor of women that is strongly increasing with the extent of a field's male-domination. This bias turns from 3 to 5 percentile ranks for men in literature and foreign languages to about 10 percentile ranks for women in math, physics, or philosophy. These findings have implications for the debate over what interventions are appropriate to increase the representation of women in fields in which they are currently underrepresented. Copyright 2016 by the American Association for the Advancement of Science. All rights reserved. dominance; female behavior; gender disparity; human behavior; male; science and technology; social problem; teaching; academic achievement; accreditation; Article; chemistry; emotional intelligence; female; France; gender bias; geography; high school; history; human; male; mathematics; philosophy; physics; primary school; priority journal; sex difference; sex ratio; sociology; teacher; teaching; education; engineering; psychology; science; sexism; social dominance; technology; France; Accreditation; Educational Measurement; Engineering; Female; France; Humans; Male; Mathematics; Science; Sexism; Social Dominance; Technology  	L-90	SDG5	1	null	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-25	SDG7	1	null	null
Q062822	Coupling between adsorption and mechanics (and vice versa) Adsorption can deform porous solids, and mechanical stresses or strains can impact the adsorption process: this mini-review is dedicated to this coupling. After introducing some frameworks used to predict adsorption-induced strains, the question of how important it is to take into account the impact of mechanics on the adsorption process is addressed. Finally, some specific complexities (e.g. of the microstructure, or of the mechanical behavior of the adsorbent) that the community aims at integrating into the prediction of adsorption-induced strains are addressed. 2018 Elsevier Ltd Elasticity; Structural design; Adsorption process; Induced strain; Mechanical behavior; Mechanical stress; Porous solids; Adsorption  	L-87	SDG7	1	null	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-23	SDG4	1	null	null
Q073116	Engineering students' use of creativity and development tools in conceptual product design: What, when and how? As creativity has become a requisite skill for engineers and a part of their basic training, one of the challenges in engineering education is to supply students with a good understanding of creativity and development tools. The aim of this study was to assess the effectiveness of these tools during a conceptual product design challenge. Students were introduced to creativity and development techniques and were provided the opportunity to choose and apply various methods during a hands-on project over 10 sessions distributed over 8 weeks. The analysis of the workbook used to record their progress showed individual differences in the creative process stages and performance as well as the nature of the tools used, when these tools were applied, and their effectiveness. The most creative students (C+) came up with original unique concepts, employed significantly more tools than the less creative ones (C-) and sustained their effort to find ideas up to the very end of the project. Most students who used Analogies, Personas, mind mapping, purge, and/or reverse brainstorming produced unique ideas, a variety of concepts as well as technological innovations. Structured and rational methods, such as functional analysis were used by both groups C+ and C-. This structured approach resulted in a mere reformulation of the specifications’ brief that helped students to clarify the problem and to better understand the functions and the constraints and they felt “ready to get started”. As it was observed with TRIZ, FAST, SADT, APTE and IRAD, the majority (78%) of the students who applied functional analysis did not come up with any unique or original kitchen concepts. The findings are discussed in relation to the effectiveness of the creativity training to improve the students’ confidence in their creative potential, as well as the fit between the tools used and (a) the conceptual design challenge, (b) the phase of the creative process, and (c) individual preferences such as the need for structure and closure. 2017 Elsevier Ltd Conceptual design; Creativity; Education; Engineering  	L-66	SDG4	1	null	null
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-39	SDG5	1	null	null
Q093239	Competitive Schools and the Gender Gap in the Choice of Field of Study In most developed countries, students have to choose a major field of study during high school. This is an important decision because it largely determines subsequent educational and occupational choices. Using French data, this paper reveals that enrollment at a more selective high school, with higher-achieving peers, has no impact on boys, but a strong impact on girls' choices: they turn away from scientific fields and settle for less competitive ones. Our results are not consistent with two commonly advanced explanations for gender differences in field of study-namely, disparities in prior academic preparation and in sensitivity to rank in class. academic performance; decision making; gender disparity; secondary education; student; womens status; France  	L-90	SDG5	1	null	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-25	SDG12	1	null	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-64	SDG12	1	null	null
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-15	SDG1	1	null	null
Q123193	Financial Literacy and Asset Behaviour: Poor Education and Zero for Conduct? Financial Literacy is a specific component of human capital which allows individual to deal with fundamental financial issues so as to take adequate financial decisions. After presenting the theoretical foundations of this notion, establishing its definition and reviewing the empirical literature, this paper presents recent studies about the link between financial literacy and financial decisions of the population in France using an original survey. The results suggest that financial literacy varies across the population. It is correlated with education but also with gender, age and political affiliation. This last point could reflect differences in opinion regarding the role of welfare state and individual responsibility. Finally, the link between financial literacy and some financial behaviors (the propensity to formulate a specific financial plan in the long run on the one hand and the propensity to own stocks on the other hand) is evaluated: in both cases positive correlations with financial literacy variables are found. We conclude with a reflection on the relative status of financial education to explain the investments of households and judge the effectiveness of training programs in the economic culture. 2018 Association for Comparative Economic Studies. Financial literacy; Propensity to plan; Saving; Stock participation puzzle; Wealth  	L-86	SDG1	1	null	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-66	SDG3	1	null	null
Q133258	Premature mortality and poverty measurement in an OLG economy Following Kanbur and Mukherjee (Bull Econ Res 59(4):339–359 2007), a solution to the “missing poor” problem (i.e., selection bias in poverty measures due to income-differentiated mortality) consists in computing hypothetical poverty rates while assigning a fictitious income to the prematurely dead. However, in a dynamic general equilibrium economy, doing “as if” the prematurely dead were still alive is likely to affect wages, output and capital accumulation, with an uncertain effect on poverty. We develop a three-period OLG model with income-differentiated mortality and compare actual poverty rates with hypothetical poverty rates that would have prevailed if everyone faced the survival conditions of the top income class. Including the prematurely dead has an ambiguous impact on poverty, since it affects income distribution through capital dilution, composition effects, and horizon effects. Our results are illustrated by quantifying the impact of income-differentiated mortality on poverty measures for France (1820–2010). 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Capital accumulation; Income-differentiated mortality; Missing poor; OLG models; Poverty measures  	L-93	SDG3	1	null	null
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-24	SDG2	1	null	null
Q182183	Use of probabilistic expert elicitation for assessing risk of appearance of grape downy mildew Grape downy mildew (GDM) is a major disease of grapevine and the date of appearance of its first symptoms is a determinant information for the protection of the vineyard. Probabilistic elicitation of experts has been used here to estimate this date. In 2017 and 2018, 29 experts were elicited to provide probability distributions of dates of GDM appearance between April and June, for different plots. The results of these elicitations show that the experts' forecasts and their uncertainty change over the season with possible consequences on the number of fungicide treatments. The elicited dates tend to be earlier at the beginning of the season and later at the end of the season, with an average difference of about 18 days. In April 2017 and 2018, most of the elicited dates are too early compared to observed dates of GDM symptom appearance. However, this bias becomes negligible in the month of May. Compared to qualitative scoring systems, our results indicate that probabilistic elicitation is a better tool for communicating expert judgments and their associated uncertainties in plant disease risk assessments and epidemiological alert bulletins. 2019 Elsevier Ltd Downy mildew; Expert judgment; Grapevine; Probabilistic elicitation; Uncertainty comparative study; disease prevalence; environmental assessment; epidemiology; expert system; fungal disease; fungicide; probability; risk assessment; symptom; uncertainty analysis; vine; vineyard; Peronosporaceae; Vitaceae; Vitis  	L-87	SDG2	1	null	null
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-15	SDG2	1	null	null
Qhal02883565	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated.  	L-20	SDG2	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-38	SDG15	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-66	SDG13	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-66	SDG15	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-66	SDG16	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-69	SDG11	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-75	SDG11	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-75	SDG13	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-88	SDG11	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-88	SDG13	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-88	SDG15	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-88	SDG16	1	null	null
Q09hal01995271	Rural areas: between dependence and autonomy of metropolises - The case of the Vosges du Nord NRP In the framework of the Clim'Ability (2016-2019) research, which aims to support companies in taking into account climate change on the scale of the Upper Rhine, case studies have been conducted. Their objective was to refine knowledge on companies' capacities to adapt to climate change in order to determine how the territory can influence awareness and action (the territory as a geographical entity knowledge of specific hazards due to local characteristics, but also the territory as an institutional structure and space of appropriation) (Rudolf, 2012; Gobert et al., 2017). One of these field studies was particularly interested in the Vosges du Nord Regional Nature Park and the wood-forest sector (Brailly, 2012). As a rural territory characterized by its status, its charter and its landscapes, the NRP is partly subject to external influences such as the metropolis of Strasbourg (especially in terms of mobility of inhabitants) and the structuring of economic markets, including that of wood. It also presents a certain number of its own endogenous forces, material assets (natural resources in particular) and immaterial assets (skills present on the territory, partly linked to the industrial past and present companies. This article sets out to determine which entities are active in the territory and how they can structure the future of the territory, focusing on the efforts made in a particular sector of activity, that of the exploitation of the forest and of the material that is wood. Sector , Wood , Circular economy , Metropolises , etc.  	L-93	SDG16	1	null	null
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-24	SDG8	1	null	null
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-25	SDG8	1	null	null
Q17halshs02491753	Dark Matter Credit: The Development of Peer-to-Peer Lending and Banking in France How a vast network of shadow credit financed European growth long before the advent of banking Prevailing wisdom dictates that, without banks, countries would be mired in poverty. Yet somehow much of Europe managed to grow rich long before the diffusion of banks. Dark Matter Credit draws on centuries of cleverly collected loan data from France to reveal how credit abounded well before banks opened their doors. This incisive book shows how a vast system of shadow credit enabled nearly a third of French families to borrow in 1740, and by 1840 funded as much mortgage debt as the American banking system of the 1950s. Dark Matter Credit traces how this extensive private network outcompeted banks and thrived prior to World War I—not just in France but in Britain, Germany, and the United States—until killed off by government intervention after 1918. Overturning common assumptions about banks and economic growth, the book paints a revealing picture of an until-now hidden market of thousands of peer-to-peer loans made possible by a network of brokers who matched lenders with borrowers and certified the borrowers’ creditworthiness. A major work of scholarship, Dark Matter Credit challenges widespread misperceptions about French economic history, such as the notion that banks proliferated slowly, and the idea that financial innovation was hobbled by French law. By documenting how intermediaries in the shadow credit market devised effective financial instruments, this compelling book provides new insights into how countries can develop and thrive today.  	L-64	SDG8	1	null	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-23	SDG16	1	null	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-42	SDG16	1	null	null
Q24halshs02413366	Paris, a Contested Construction of Metropolitan Space This chapter tells the story of the difficult and contested efforts to construct Paris as a metropolitan space. Covering the period of 2000 to the present, it focuses on the search for a collective actor and the production of collective action through the quest for alliances between players, be they the central State, local governments or business associations. More specifically, the chapter concentrates on the relationships between core metropolitan stakeholders through the analysis of four political initiatives aiming at building collective action and territorial leadership at the metropolitan scale. In the Île-de-France region, many competing conceptions of metropolitan space are co-present and are conflicting. First the regional council, whatever its political leaning, has always considered the Metropolis to be the Île-de-France region. In that perspective the construction of metropolitan space is understood to mean the strengthening of the powers and resources of the regional authority. Second, the city of Paris considers the core area to be the most relevant space to address the important problems of the metropolis. Third, the State maintains an ambiguous position as regards its conception of the metropolitan space, identifying it as the city region in the period 2007–2012 when the State was controlled by the conservative parties, but restricting it to the core area in the period 2012–2017 by the new Socialist government. In this context, the most important business associations have been ready to accommodate any initiative, provided that the treatment of the most important issues of economic competitiveness, transport and housing, was taken care of. This story clearly indicates the importance of politics in the construction of metropolitan space and shows the critical role that politics plays in shaping scalar conflicts. In this context, decentralization and globalization can be understood to be both structuring forces and elements which are instrumentalized. First, there is the issue of territorial leadership which has consistently led to a stalemate, because of a governance system whose main feature, unregulated competitive decentralization, prevents any leader from being accepted as legitimate at a regional scale. Second, the building of a coalition at the metropolitan level, to ensure capacity to act at that scale, has proved impossible, first, because of a relative balance of powers between local governments and, second, because of the incapacity of the State to successfully act as the leader of a coalition because of its political instability and its lack of resources. Third, players also conflict about the vision they have of the future of the metropolitan area. Two clearly opposed visions coexist, one in which priorities are to fight against social and territorial inequalities and to initiate an alternative mode of development based on ecological transition, another one in which economic competitiveness is the top priority to which social, territorial and environmental issues must be subordinated. Since these two visions are supported by alliances of players which are roughly equal in strength, the not surprising result is conflict and the blockage of the governance system.	L-88	SDG16	1	null	null
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-14	SDG11	1	null	null
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-26	SDG11	1	null	null
Q46	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Doubling throughput in urban roads by platooning Intersections are the bottlenecks of the urban road system because an intersection's capacity is only a fraction of the vehicle flows that the roads connecting to the intersection can carry. The saturation flow rate, and hence the capacity, can be doubled if vehicles can cross intersections in platoons rather than one by one as they do today. Platoon formation is enabled by connected vehicle technology. Doubling the saturation flow rate has dramatic mobility benefits: the throughput of the road system can be doubled without changing the signal control, or vehicle delay can be reduced by reducing the cycle time. These predictions draw on an analysis of a queuing model of a signalized network with fixed time control and they are validated in a simulation of a small urban network with 16 intersections and 73 links. 2016 adaptive control; Connected vehicles; platooning; reducing delay; saturation flows Queueing theory; Roads and streets; Traffic signals; Vehicles; Adaptive Control; platooning; reducing delay; Saturation flow; Saturation flow rates; Signal control; Urban networks; Vehicle technology; Transportation  	C-42	SDG11	1	null	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-22	SDG7	1	null	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-26	SDG7	1	null	null
Q52	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? New parallelizable schemes for integrating the Dissipative Particle Dynamics with Energy conservation This work presents new parallelizable numerical schemes for the integration of dissipative particle dynamics with energy conservation. So far, no numerical scheme introduced in the literature is able to correctly preserve the energy over long times and give rise to small errors on average properties for moderately small time steps, while being straightforwardly parallelizable. We present in this article two new methods, both straightforwardly parallelizable, allowing to correctly preserve the total energy of the system. We illustrate the accuracy and performance of these new schemes both on equilibrium and nonequilibrium parallel simulations. 2016 AIP Publishing LLC. Physical chemistry; Dissipative particle dynamics; Non equilibrium; Numerical scheme; Parallel simulations; Time step; Total energy; Energy conservation  	C-33	SDG7	1	null	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-24	SDG7	1	null	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-25	SDG7	1	null	null
Q962	Distributed Stochastic Optimization via Matrix Exponential Learning In this paper, we investigate a distributed learning scheme for a broad class of stochastic optimization problems and games that arise in signal processing and wireless communications. The proposed algorithm relies on the method of matrix exponential learning (MXL) and only requires locally computable gradient observations that are possibly imperfect. To analyze it, we introduce the notion of a stable Nash equilibrium and we show that the algorithm is globally convergent to such equilibria - or locally convergent when an equilibrium is only locally stable. To complement our convergence analysis, we also derive explicit bounds for the algorithm's convergence speed and we test it in realistic multicarrier/multiple-antenna wireless scenarios where several users seek to maximize their energy efficiency. Our results show that learning allows users to attain a net increase between 100% and 500% in energy efficiency, even under very high uncertainty. 1991-2012 IEEE. game theory; Learning; matrix exponential learning; stochastic optimization; uncertainty; variational stability Energy efficiency; Game theory; Signal processing; Stochastic systems; Wireless telecommunication systems; Learning; Matrix exponentials; Stochastic optimizations; uncertainty; Variational stability; Optimization  	L-87	SDG7	1	null	null
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-15	SDG6	1	null	null
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-63	SDG6	1	null	null
Q1575	Polynomial Surrogates for Open-Channel Flows in Random Steady State Assessing epistemic uncertainties is considered as a milestone for improving numerical predictions of a dynamical system. In hydrodynamics, uncertainties in input parameters translate into uncertainties in simulated water levels through the shallow water equations. We investigate the ability of generalized polynomial chaos (gPC) surrogate to evaluate the probabilistic features of water level simulated by a 1-D hydraulic model (MASCARET) with the same accuracy as a classical Monte Carlo method but at a reduced computational cost. This study highlights that the water level probability density function and covariance matrix are better estimated with the polynomial surrogate model than with a Monte Carlo approach on the forward model given a limited budget of MASCARET evaluations. The gPC-surrogate performance is first assessed on an idealized channel with uniform geometry and then applied on the more realistic case of the Garonne River (France) for which a global sensitivity analysis using sparse least-angle regression was performed to reduce the size of the stochastic problem. For both cases, Galerkin projection approximation coupled to Gaussian quadrature that involves a limited number of forward model evaluations is compared with least-square regression for computing the coefficients when the surrogate is parameterized with respect to the local friction coefficient and the upstream discharge. The results showed that a gPC-surrogate with total polynomial degree equal to 6 requiring 49 forward model evaluations is sufficient to represent the water level distribution (in the sense of the l2 norm), the probability density function and the water level covariance matrix for further use in the framework of data assimilation. In locations where the flow dynamics is more complex due to bathymetry, a higher polynomial degree is needed to retrieve the water level distribution. The use of a surrogate is thus a promising strategy for uncertainty quantification studies in open-channel flows and should be extended to unsteady flows. It also paves the way toward cost-effective ensemble-based data assimilation for flood forecasting and water resource management. 2017, Springer International Publishing AG. Covariance matrix; Hydraulic modeling; Polynomial chaos expansion; Sensitivity analysis; Surrogate model; Uncertainty quantification  	L-86	SDG6	1	null	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-15	SDG3	1	null	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-26	SDG3	1	null	null
Q2112	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Insurance value of natural capital Nature-based solutions to insurance are in high demand. We explore the idea that natural capital has an insurance value insofar as it can mitigate the effects of uncertainty on human well-being. We present a formal model that substantiates this claim. We propose a definition for the insurance value of natural capital for a stochastic and dynamic ecosystem that provides ecosystem services for a risk-averse user. The insurance value of natural capital depends on the properties of ecosystem dynamics as well as on the risk and time preferences of the ecosystem user. It can be positive or negative. We relate the natural insurance value to conservative use of the ecosystem and precautionary investment in the natural capital stock. For the case of logarithmic per-period utility we find that optimal management becomes more conservative with increasing uncertainty if and only if the insurance value of natural capital is positive. We qualify this finding for more general forms of the per-period utility function. 2019 The Authors Ecological-economic modeling; Natural capital; Natural insurance; Precautionary investment; Prudence; Risk aversion demand analysis; ecological economics; ecosystem dynamics; ecosystem service; natural capital; risk assessment  	C-33	SDG3	1	null	null
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-15	SDG3	1	null	null
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-26	SDG3	1	null	null
Q2151	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Statistical ranking of electromechanical dyssynchrony parameters for CRT Objective Mechanical evaluation of dyssynchrony by echocardiography has not replaced ECG in routine cardiac resynchronisation therapy (CRT) evaluation because of its complexity and lack of reproducibility. The objective of this study was to evaluate the potential correlations between electromechanical parameters (atrioventricular, interventricular and intraventricular from the dyssynchrony model presented in 2000), their ability to describe dyssynchrony and their potential use in resynchrony. Methods 455 sets of the 18 parameters of the model obtained in 91 patients submitted to various pacing configurations were evaluated two by two using a Pearson correlation test and then by groups according to their ability to describe dyssynchrony, using the Column selection method of machine learning. Results The best parameter is duration of septal contraction, which alone describes 25% of dyssynchrony. The best groups of 3, 4 and =8 variables describe 59%, 73% and almost 100% of dyssynchrony, respectively. Left pre-ejection interval is highly and significantly correlated to a maximum of other variables, and its decrease is associated with the favourable evolution of all other correlated parameters. Increase in filling duration and decrease in duration of septum to lateral wall contraction difference are not associated with the favourable evolution of other parameters. Conclusions No single electromechanical parameter alone can fully describe dyssynchrony. The 18-parameter model can be simplified, but still requires at least 4-8 parameters. Decrease in left pre-ejection interval favourably drives resynchrony in a maximum of other parameters. Increase in filling duration and decrease in septum-lateral wall difference do not appear to be good CRT targets. Author(s) (or their employer(s)) 2019. cardiac resynchronization therapy; electromechanical parameters; left pre-ejection interval; resynchrony adult; animal experiment; animal model; article; cardiac resynchronization therapy; controlled study; female; machine learning; male; muscle contractility; nonhuman  	C-33	SDG3	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-15	SDG9	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-22	SDG2	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-26	SDG2	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-26	SDG9	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-40	SDG2	1	null	null
Q2527	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Risk and Sustainability: Assessing Fishery Management Strategies We develop a theoretical framework to assess the sustainability of fishery management strategies, when the bioeconomic dynamics are marked by uncertainty and several conflicting objectives have to be accounted for. Stochastic viability ranks management strategies according to their probability to sustain economic and ecological outcomes over time. The approach is extended to build stochastic sustainable production possibility frontiers representing the trade-offs between sustainability objectives at any risk level, given the current state of the fishery. This framework is applied to a Chilean fishery faced with El Niño uncertainty. We study the viability of effort and quota strategies when catch and biomass levels have to be sustained. We show that (1) for these sustainability objectives, whatever the level of the outcomes to be sustained, quota-based management results in a better viability probability than effort-based management, and (2) the fishery’s historical quota levels were not sustainable given the stock levels in the early 2000s. 2015, Springer Science+Business Media Dordrecht. Fishery economics and management; Risk; Stochastic viability; Sustainability Economic and social effects; Fisheries; Risk assessment; Risks; Stochastic systems; Uncertainty analysis; Conflicting objectives; Fishery economics; Fishery management; Management strategies; Stochastic viability; Sustainability objectives; Sustainable production; Theoretical framework; Sustainable development; biomass; El Nino; fishery economics; fishery management; risk assessment; strategic approach; sustainability; viability; Chile  	C-41	SDG9	1	null	null
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-15	SDG14	1	null	null
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-17	SDG14	1	null	null
Q12359	High-resolution neodymium characterization along the Mediterranean margins and modelling of Nd distribution in the Mediterranean basins An extensive compilation of published neodymium (Nd) concentrations and isotopic compositions (Nd IC) was realized in order to establish a new database and a map (using a high-resolution geological map of the area) of the distribution of these parameters for all the Mediterranean margins. Data were extracted from different kinds of samples: river solid discharge deposited on the shelf, sedimentary material collected on the margin or geological material outcropping above or close to a margin. Additional analyses of surface sediments were done in order to improve this data set in key areas (e.g. Sicilian strait). The Mediterranean margin Nd isotopic signatures vary from non-radiogenic values around the Gulf of Lion, ( Nd values~11) to radiogenic values around the Aegean and the Levantine sub-basins up to +6. Using a high-resolution regional oceanic model (1/12° of horizontal-resolution), Nd distribution was simulated for the first time in the Mediterranean Sea. The high resolution of the model provides a unique opportunity to represent a realistic thermohaline circulation in the basin and thus apprehend the processes governing the Nd isotope distribution in the marine environment. Results are consistent with the preceding conclusions on boundary exchange (BE) as an important process in the Nd oceanic cycle. Nevertheless this approach simulates a too-radiogenic value in the Mediterranean Sea; this bias will likely be corrected once the dust and river inputs will be included in the model. This work highlights that a significant interannual variability of Nd distribution in seawater could occur. In particular, important hydrological events such as the Eastern Mediterranean Transient (EMT), associated with deep water formed in the Aegean sub-basin, could induce a shift in Nd at deep/intermediate depths that could be noticeable in the eastern part of the basin. This underlines that the temporal and geographical variations of Nd could represent an interesting insight of Nd as tracer of the Mediterranean Sea circulation, in particular in the context of palaeo-oceanographic applications. 2016 Author(s). concentration (composition); continental shelf; database; deep water formation; geographical variation; ion exchange; isotopic composition; Mediterranean environment; neodymium isotope; sediment chemistry; thermohaline circulation; Gulf of Lion; Mediterranean Sea  	L-74	SDG14	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-24	SDG8	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-25	SDG8	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-87	SDG8	1	null	null
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-24	SDG1	1	null	null
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-25	SDG1	1	null	null
Q011335	Assessment of integration method for displacement determination using field accelerometer and geophone data A conventional French railway track was instrumented with accelerometers and geophones at three depths: sleeper (surface), interlayer (ITL, z=-0.93 m), and transition layer (TL, z=-1.20 m). A linear variable differential transformer (LVDT) was also used to monitor the displacement at the sleeper level. The recorded data allow the integration method (double for accelerometer and simple for geophone) for displacement determination to be assessed. Several questions need to be addressed prior to the selection of an adequate monitoring system: definition of signal filtering processes, influence on results of the different loading wavelengths, repeatability of measurements, train speed and axle load impact and their ranges of validity for each sensor. It was found that the main frequencies that caused more than 95% of the displacement of the monitored materials are in the low frequency range: <25 Hz for trains running up to 200 km/h. For an intercity train, the low frequencies are normally excited by long wavelengths, for instance, those corresponding to the 1/2 coach distance (?=13.20 m), the bogies distance (?=6.3 m), and the axle distance (?=2.8 m). Comparison between the displacements deduced from the records of accelerometer and geophone and obtained from the records of LVDT shows quite consistent results; the mean displacement amplitudes obtained from accelerometers differ by only 20% from the LVDT records. The train speed does not have a strong effect on the obtained differences between sensors. The embedded sensors also gave consistent displacement results for each analysed depth. Moreover, the displacement amplitudes caused by different axle loads (locomotive or passenger coach) are distinguishable for all sensors at all depths. This validates the integration method used for the displacement determination. 2017, Zhejiang University and Springer-Verlag GmbH Germany. Accelerometer; Deflection amplitude estimation; Geophone; Integration method; Linear variable differential transformer (LVDT); Measurement repeatability; Railway track; Vibrations Accelerometers; Axles; Integration; Loads (forces); Passenger cars; Railroad tracks; Railroad transportation; Railroads; Signal processing; Deflection amplitude; Geophone; Integration method; Linear variable differential transformer; Measurement repeatability; Railway track; Vibrations; Data integration  	L-87	SDG1	1	null	null
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-24	SDG13	1	null	null
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-54	SDG13	1	null	null
Q211168	The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated According to climate model simulations, the changing altitude of middle and high clouds is the dominant contributor to the positive global mean longwave cloud feedback. Nevertheless, the mechanisms of this longwave cloud altitude feedback and its magnitude have not yet been verified by observations. Accurate, stable, and long-term observations of a metric-characterizing cloud vertical distribution that are related to the longwave cloud radiative effect are needed to achieve a better understanding of the mechanism of longwave cloud altitude feedback. This study shows that the direct measurement of the altitude of atmospheric lidar opacity is a good candidate for the necessary observational metric. The opacity altitude is the level at which a spaceborne lidar beam is fully attenuated when probing an opaque cloud. By combining this altitude with the direct lidar measurement of the cloud-top altitude, we derive the effective radiative temperature of opaque clouds which linearly drives (as we will show) the outgoing longwave radiation. We find that, for an opaque cloud, a cloud temperature change of 1 K modifies its cloud radiative effect by 2 W m-2. Similarly, the longwave cloud radiative effect of optically thin clouds can be derived from their top and base altitudes and an estimate of their emissivity. We show with radiative transfer simulations that these relationships hold true at single atmospheric column scale, on the scale of the Clouds and the Earth's Radiant Energy System (CERES) instantaneous footprint, and at monthly mean 2° × 2° scale. Opaque clouds cover 35 % of the ice-free ocean and contribute to 73 % of the global mean cloud radiative effect. Thin-cloud coverage is 36 % and contributes 27 % of the global mean cloud radiative effect. The link between outgoing longwave radiation and the altitude at which a spaceborne lidar beam is fully attenuated provides a simple formulation of the cloud radiative effect in the longwave domain and so helps us to understand the longwave cloud altitude feedback mechanism. accuracy assessment; altitude; climate modeling; cloud cover; lidar; longwave radiation; measurement method; radiative transfer; SIR; vertical distribution  	L-92	SDG13	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-15	SDG16	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-17	SDG16	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-78	SDG16	1	null	null
Q11hal01542409	Urban Ecology Contemporary ideas of nature were largely shaped by schools of thought from Western cultural history and philosophy until the present-day concerns with environmental change and biodiversity conservation. There are many different ways of conceptualising nature in epistemological terms, reflecting the tensions between the polarities of humans as masters or protectors of nature and as part of or outside of nature. The book shows how nature is today the focus of numerous debates, calling for an approach which goes beyond the merely technical or scientific. It adopts a threefold – critical, historical and cross-disciplinary – approach in order to summarise the current state of knowledge. It includes contributions informed by the humanities (especially history, literature and philosophy) and social sciences, concerned with the production and circulation of knowledge about nature across disciplines and across national and cultural spaces. The volume also demonstrates the ongoing reconfiguration of subject disciplines, as seen in the recent emergence of new interdisciplinary approaches and the popularity of the prefix eco- (e.g. ecocriticism, ecospirituality, ecosophy and ecofeminism, as well as subdivisions of ecology, including urban ecology, industrial ecology and ecosystem services). Each chapter provides a concise overview of its topic which will serve as a helpful introduction to students and a source of easy reference.  This text is also valuable reading for researchers interested in philosophy, sociology, anthropology, geography, ecology, politics and all their respective environmentalist strands. Ecology , Nature , City	L-86	SDG16	1	null	null
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-25	SDG11	1	null	null
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-50	SDG11	1	null	null
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-54	SDG11	1	null	null
Q174	Stations in the mirror of the urban Composed of 5 articles, this issue of the journal Flux is part of the continuation of the doctoral seminar Les gares au miroir de l'urbain (Stations in the mirror of the urban), which will be held in 2013 as a place for debate on the various research projects on the hybrid objects that constitute stations. Starting from a feeling of saturation, or even overflow, linked to the omnipresence of the station in the discourse on urban planning, the seminar intended to question the supposed nature of the tensions between station and urban, and in particular this double process of interaction which would like this couple. On the one hand, stations seem to capture and embody the tensions that work and transform the urban; this leads to an accumulation - crystallization of the urban in the microcosm of the station, without the station covering or totally embodying the urban. On the other hand, stations, in their imagination, their models and their development processes, project visions and practices into the field of the urban, which acculturate and transform themselves in contact with these socio-technical transformations. It is this double process of condensation and aspiration that we wanted to question through the various invited papers. The contributors to the seminar and to this issue were solicited on several criteria: first, on the contribution of their research to the understanding of this station-urban couple, according to different horizons, historical on the construction of an urbanite, sociological on the question of surveillance, geographical on the micro-experience located or on the metropolitan macro scale, political on the controversies as to the future heritage of stations. Then on the way in which their fields of research reinterviewed urban research. Finally on the contribution of peripheral offsets to renew the perspective of understanding the station object.  	L-92	SDG11	1	null	null
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-14	SDG3	1	null	null
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-15	SDG3	1	null	null
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-22	SDG3	1	null	null
Q2124	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Robust viability analysis of a controlled epidemiological model Managing infectious diseases is a world public health issue, plagued by uncertainties. In this paper, we analyze the problem of viable control of a dengue outbreak under uncertainty. For this purpose, we develop a controlled Ross–Macdonald model with mosquito vector control by fumigation, and with uncertainties affecting the dynamics; both controls and uncertainties are supposed to change only once a day, then remain stationary during the day. The robust viability kernel is the set of all initial states such that there exists at least a strategy of insecticide spraying which guarantees that the number of infected individuals remains below a threshold, for all times, and whatever the sequences of uncertainties. Having chosen three nested subsets of uncertainties – a deterministic one (without uncertainty), a medium one and a large one – we can measure the incidence of the uncertainties on the size of the kernel, in particular on its reduction with respect to the deterministic case. The numerical results show that the viability kernel without uncertainties is highly sensitive to the variability of parameters — here the biting rate, the probability of infection to mosquitoes and humans, and the proportion of female mosquitoes per person. So, a robust viability analysis is a possible tool to reveal the importance of uncertainties regarding epidemics control. 2019 Elsevier Inc. Dengue; Epidemics control; Ross–Macdonald model; Uncertainty and robustness; Viability dengue fever; disease control; disease vector; epidemiology; infectious disease; numerical model; parameter estimation; population outbreak; population viability analysis; public health; uncertainty analysis; insecticide; animal; biological model; Colombia; dengue; epidemic; female; growth, development and aging; human; insect vector; Markov chain; microbial viability; mosquito; mosquito control; procedures; Animals; Colombia; Culicidae; Dengue; Disease Outbreaks; Female; Humans; Insect Vectors; Insecticides; Microbial Viability; Models, Biological; Mosquito Control; Stochastic Processes  	C-26	SDG3	1	null	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-15	SDG13	1	null	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-37	SDG13	1	null	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-46	SDG13	1	null	null
Q2559	How robust are stratospheric age of air trends from different reanalyses? An accelerating Brewer-Dobson circulation (BDC) is a robust signal of climate change in model predictions but has been questioned by trace gas observations. We analyse the stratospheric mean age of air and the full age spectrum as measures for the BDC and its trend. Age of air is calculated using the Chemical Lagrangian Model of the Stratosphere (CLaMS) driven by ERA-Interim, JRA-55 and MERRA-2 reanalysis data to assess the robustness of the representation of the BDC in current generation meteorological reanalyses. We find that the climatological mean age significantly depends on the reanalysis, with JRA-55 showing the youngest and MERRA-2 the oldest mean age. Consideration of the age spectrum indicates that the older air for MERRA-2 is related to a stronger spectrum tail, which is likely associated with weaker tropical upwelling and stronger recirculation. Seasonality of stratospheric transport is robustly represented in reanalyses, with similar mean age variations and age spectrum peaks. Long-Term changes from 1989 to 2015 turn out to be similar for the reanalyses with mainly decreasing mean age accompanied by a shift of the age spectrum peak towards shorter transit times, resembling the forced response in climate model simulations to increasing greenhouse gas concentrations. For the shorter periods, 1989-2001 and 2002-2015, the age of air changes are less robust. Only ERA-Interim shows the hemispheric dipole pattern in age changes from 2002 to 2015 as viewed by recent satellite observations. Consequently, the representation of decadal variability of the BDC in current generation reanalyses appears less robust and is a major uncertainty of modelling the BDC. Author(s) 2019. atmospheric circulation; climate modeling; climatology; Lagrangian analysis; long-term change; seasonality; stratosphere; trend analysis; Bivalvia    	L-86	SDG13	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-66	SDG11	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-66	SDG15	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-88	SDG11	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-88	SDG15	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-90	SDG11	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-90	SDG15	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-93	SDG11	1	null	null
Q3117	In search of features that constitute an enriched environment in humans: Associations between geographical properties and brain structure Enriched environments elicit brain plasticity in animals. In humans it is unclear which environment is enriching. Living in a city has been associated with increased amygdala activity in a stress paradigm, and being brought up in a city with increased pregenual anterior cingulate cortex (pACC) activity. We set out to identify geographical characteristics that constitute an enriched environment affecting the human brain. We used structural equation modelling on 341 older adults to establish three latent brain factors (amygdala, pACC and dorsolateral prefrontal cortex (DLPFC)) to test the effects of forest, urban green, water and wasteland around the home address. Our results reveal a significant positive association between the coverage of forest and amygdala integrity. We conclude that forests may have salutogenic effects on the integrity of the amygdala. Since cross-sectional data does not allow causal inference it could also be that individuals with high structural integrity choose to live closer to forest. 2017 The Author(s). aged; amygdala; anatomy and histology; cingulate gyrus; cross-sectional study; environmental exposure; Germany; growth, development and aging; human; middle aged; prefrontal cortex; very elderly; Aged; Aged, 80 and over; Amygdala; Cross-Sectional Studies; Environmental Exposure; Germany; Gyrus Cinguli; Humans; Middle Aged; Prefrontal Cortex  	L-93	SDG15	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-24	SDG1	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-25	SDG1	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-87	SDG1	1	null	null
Q16488	Barriers and (im)mobility in Rio de Janeiro In Rio de Janeiro, immobility or the share of people with no journeys on any given day is very high (46%). Immobility has a marked geographical dimension in what is a segregated city. But income has only limited explanatory power. The population structure, with high proportions of people who are not in the labour force and who are unemployed, accounts for the high levels of immobility in the poor districts. Although population structure effects prevail, spatial factors such as the severance effect also account for differences between districts. Indeed, Rio de Janeiro features many different types of barriers that affect immobility in several districts and for several population groups. These barriers may be physical or symbolic and perceptive. This study proposes therefore to identify the scope of those barriers as they affect immobility. Our findings from the latest household travel survey available for the metropolitan area of Rio de Janeiro (2003) illustrate the effects of the two types of barrier, physical or symbolic and perceptive, on immobility that more specifically mark out certain categories of individuals such as housewives, the elderly, the unemployed or poor workers. Conversely, the wealthier active population seems to be little affected by the two types of barriers under study. Lastly, our results show that social fragmentation does not lead to greater immobility of favela populations in the heart of rich districts, but on the contrary to increased mobility, especially for the working age population in employment or looking for employment. 2015, Urban Studies Journal Limited 2015. barriers; Brazil; built environment; immobility; mobility; severance effect; transport age structure; household survey; labor mobility; metropolitan area; migratory behavior; population structure; unemployment; wage; Brazil; Rio de Janeiro [Brazil]  	L-92	SDG1	1	null	null
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-23	SDG12	1	null	null
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-88	SDG12	1	null	null
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-90	SDG12	1	null	null
Q083169	CSR Needs CPR: Corporate Sustainability and Politics Corporate sustainability has gone mainstream, and many companies have taken meaningful steps to improve their own environmental performance. But while corporate political actions such as lobbying can have a greater impact on environmental quality, they are ignored in most current sustainability metrics. It is time for these metrics to be expanded to critically assess firms based on the sustainability impacts of their public policy positions. To enable such assessments, firms must become as transparent about their corporate political responsibility (CPR) as their corporate social responsibility (CSR). For their part, rating systems must demand such information from firms and include evaluations of corporate political activity in their assessments of corporate environmental responsibility. The Regents of the University of California 2018. Business & society; Business-government relations; Corporate social responsibility; Lobbying; Non-market strategy; Policy making; Sustainability  	L-94	SDG12	1	null	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-24	SDG13	1	null	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-25	SDG13	1	null	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-87	SDG13	1	null	null
Q111044	Dynamics and sources of last glacial aeolian deposition in southwest France derived from dune patterns, grain-size gradients and geochemistry, and reconstruction of efficient wind directions Dune pattern, grain-size gradients and geochemistry were used to investigate the sources and dynamics of aeolian deposition during the last glacial in southwest France. The coversands form widespread fields of low-amplitude ridges (zibars), whereas Younger Dryas parabolic dunes mainly concentrate in corridors and along rivers. Spatial modelling of grain-size gradients combined with geochemical analysis points to a genetic relationship between coversands and loess, the latter resulting primarily from dust produced by aeolian abrasion of the coversands. The alluvium of the Garonne river provided also significant amounts of dust at a more local scale. The geochemical composition of loess shows much lower scattering than that of coversands, due to stronger homogenisation during transport in the atmosphere. Overall, sandy loess and loess deposits decrease in thickness away from the coversands. Dune orientation and grain-size gradients suggest that the efficient winds blew respectively from the W to the NW during the glacial, and the W-SW during the Younger Dryas. A comparison between the wind directions derived from the proxy data and those provided by palaeoclimatic simulations suggests a change of the main transport season. Ground surface conditions and their evolution throughout the year, i.e. the length of the season with snow and frozen or moist topsoil, and the seasonal distribution of wind speeds able to cause deflation are thought to have been the main factors that controlled the transport season in the study area. 2017 Elsevier Ltd Coversand; Dunes; Geochemistry; Grain-size modelling; Last glacial; Loess; Southwest France; Wind direction Air pollution control; Analytical geochemistry; Deposition; Dust; Geochemistry; Glacial geology; Sediments; Coversand; Dunes; Grain size; Last glacial; Loess; Southwest France; Wind directions; Bacteriology; abrasion; alluvial deposit; deflation; dune; eolian deposit; geochemistry; grain size; Last Glacial; loess; paleoclimate; reconstruction; sand; sediment transport; spatial distribution; wind direction; wind erosion; Younger Dryas; France; Garonne River  	L-92	SDG13	1	null	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-21	SDG2	1	null	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-30	SDG2	1	null	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-70	SDG2	1	null	null
Qhal02883566	Ecological compensation and Agriculture Biodiversity Offset Measures (BOMs) are actions that ensure ecological gains at least equivalent to the losses incurred as a result of a development project. The Biodiversity Law of August 2016 makes the CBM framework more coercive. While 60% of French territory is dedicated to agricultural practices, farmers should become major players in ecological compensation. We analyze through a choice experiment the preferences of farmers to become MC operators. We show that the requirements of CD contracts will not lead to a systematic adhesion of farmers. We suggest contract orientations by farmer profile and by type of impacts to be compensated. Abel , Bible , Roman médiéval , Caïn	L-88	SDG2	1	null	null
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-14	SDG11	1	null	null
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-22	SDG11	1	null	null
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-26	SDG11	1	null	null
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-34	SDG11	1	null	null
Q195	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A sensitivity study of road transportation emissions at metropolitan scale A sensitivity study of road transportation emissions at metropolitan scale  	C-35	SDG11	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-60	SDG7	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-62	SDG7	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-70	SDG7	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-88	SDG7	1	null	null
Q1583	Equilibrium modeling of the beach profile on a macrotidal embayed low tide terrace beach Eleven-year long time series of monthly beach profile surveys and hourly incident wave conditions are analyzed for a macrotidal Low Tide Terrace beach. The lower intertidal zone of the beach has a pluriannual cycle, whereas the upper beach profile has a predominantly seasonal cycle. An equilibrium model is applied to study the variation of the contour elevation positions in the intertidal zone as a function of the wave energy, wave power, and water level. When forcing the model with wave energy, the predictive ability of the equilibrium model is around 60% in the upper intertidal zone but decreases to 40% in the lower intertidal zone. Using wave power increases the predictive ability up to 70% in both the upper and lower intertidal zones. However, changes around the inflection point are not well predicted. The equilibrium model is then extended to take into account the effects of the tide level. The initial results do not show an increase in the predictive capacity of the model, but do allow the model free parameters to represent more accurately the values expected in a macrotidal environment. This allows comparing the empirical model calibration in different tidal environment. The interpretation of the model free parameter variation across the intertidal zone highlights the behavior of the different zones along the intertidal beach profile. This contributes to a global interpretation of the four model parameters for beaches with different tidal ranges, and therefore to a global model applicable at a wide variety sites. 2018, Springer-Verlag GmbH Germany, part of Springer Nature. Cross-shore processes; Equilibrium model; Intertidal profile; Low tide terrace; Macrotidal Tides; Water levels; Wave energy conversion; Wave power; Equilibrium modeling; Inflection points; Intertidal profile; Low tide terraces; Macrotidal; Predictive abilities; Predictive capacity; Tidal environments; Beaches; annual cycle; beach profile; calibration; equilibrium; intertidal environment; numerical model; parameter estimation; seasonal variation; terrace; wave energy; wave power  	L-90	SDG7	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-6	SDG6	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-6	SDG7	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-15	SDG6	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-15	SDG7	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-26	SDG6	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-26	SDG7	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-32	SDG6	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-32	SDG7	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-33	SDG6	1	null	null
Q2122	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? An explicit pseudo-energy conserving time-integration scheme for Hamiltonian dynamics We propose a new explicit pseudo-energy and momentum conserving scheme for the time integration of Hamiltonian systems. The scheme, which is formally second-order accurate, is based on two key ideas: the integration during the time-steps of forces between free-flight particles and the use of momentum jumps at the discrete time nodes leading to a two-step formulation for the acceleration. The pseudo-energy conservation is established under exact force integration, whereas it is valid to second-order accuracy in the presence of quadrature errors. Moreover, we devise an asynchronous version of the scheme that can be used in the framework of slow–fast time-stepping strategies. The scheme is validated against classical benchmarks and on nonlinear or inhomogeneous wave propagation problems. 2019 Elsevier B.V. Energy–momentum conservation; Explicit time-integration; Nonlinear Hamiltonian dynamics; Ordinary Differential Equations; Wave equations Energy conservation; Free flight; Integration; Momentum; Nonlinear equations; Ordinary differential equations; Wave equations; Wave propagation; Asynchronous version; Explicit time integration; Hamiltonian dynamics; Hamiltonian systems; Inhomogeneous waves; Momentum conservations; Momentum conserving; Second-order accuracy; Hamiltonians  	C-33	SDG7	1	null	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-15	SDG7	1	null	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-23	SDG7	1	null	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-26	SDG7	1	null	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-32	SDG7	1	null	null
Q2900	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable schemes for dissipative particle dynamics with conserved energy This article presents a new numerical scheme for the discretization of dissipative particle dynamics with conserved energy. The key idea is to reduce elementary pairwise stochastic dynamics (either fluctuation/dissipation or thermal conduction) to effective single-variable dynamics, and to approximate the solution of these dynamics with one step of a Metropolis–Hastings algorithm. This ensures by construction that no negative internal energies are encountered during the simulation, and hence allows to increase the admissible timesteps to integrate the dynamics, even for systems with small heat capacities. Stability is only limited by the Hamiltonian part of the dynamics, which suggests resorting to multiple timestep strategies where the stochastic part is integrated less frequently than the Hamiltonian one. 2017 Elsevier Inc. Dissipative particle dynamics; Metropolis algorithm; Numerical scheme Energy conservation; Hamiltonians; Stochastic systems; Discretizations; Dissipative particle dynamics; Internal energies; Metropolis algorithms; Numerical scheme; Single variable; Stochastic dynamics; Thermal conduction; Dynamics  	C-35	SDG7	1	null	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-15	SDG7	1	null	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-22	SDG7	1	null	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-26	SDG7	1	null	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-32	SDG7	1	null	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-33	SDG7	1	null	null
Q33	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Size consistency in smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic method that allows one to select the level of resolution at which a fluid is simulated. In this work, we study the consistency of the resulting thermodynamic properties as a function of the size of the mesoparticles, both at equilibrium and out of equilibrium. We also propose a reformulation of the SDPD equations in terms of energy variables. This increases the similarities with dissipative particle dynamics with energy conservation and opens the way for a coupling between the two methods. Finally, we present a numerical scheme for SDPD that ensures the conservation of the invariants of the dynamics. Numerical simulations illustrate this approach. 2016 American Physical Society. Condensed matter physics; Physics; Dissipative particle dynamics; Energy variables; Mesoparticles; Mesoscopic method; Numerical scheme; Out of equilibrium; Size-consistency; Dynamics  	C-35	SDG7	1	null	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-23	SDG8	1	null	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-26	SDG8	1	null	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-33	SDG8	1	null	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-34	SDG8	1	null	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-35	SDG8	1	null	null
Q204	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? A Simple GDP-based Model for Public Investments at Risk Investment decision rules in risk situations have been extensively analyzed for firms. Most research focus on financial options and the wide range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost-Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brownian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Advantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above-mentioned threshold. Some extensions are explored. Others are suggested for further research. Brownian motion; decision making; discount rate; investment; risk; risk and uncertainty DISTANT FUTURE; ENVIRONMENTAL ECONOMICS; UNCERTAINTY; IRREVERSIBILITY; DECISIONS; VALUES; TIME  	C-41	SDG8	1	null	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-6	SDG7	1	null	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-15	SDG7	1	null	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-23	SDG7	1	null	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-26	SDG7	1	null	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-33	SDG7	1	null	null
Q2875	Do you think the following publication can be considered as a contribution to achieving the goal(s) suggested below? Stable and accurate schemes for smoothed dissipative particle dynamics Smoothed dissipative particle dynamics (SDPD) is a mesoscopic particle method that allows to select the level of resolution at which a fluid is simulated. The numerical integration of its equations of motion still suffers from the lack of numerical schemes satisfying all the desired properties such as energy conservation and stability. Similarities between SDPD and dissipative particle dynamics with energy (DPDE) conservation, which is another coarse-grained model, enable adaptation of recent numerical schemes developed for DPDE to the SDPD setting. In this article, a Metropolis step in the integration of the fluctuation/dissipation part of SDPD is introduced to improve its stability. 2018, Shanghai University and Springer-Verlag GmbH Germany, part of Springer Nature. Metropolis algorithm; numerical integration; smoothed dissipative particle dynamics (SDPD) Equations of motion; Integration; Numerical methods; Coarse grained models; Dissipative particle dynamics; Mesoscopic particles; Metropolis algorithms; Numerical integrations; Numerical scheme; Dynamics  	C-35	SDG7	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-14	SDG10	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-60	SDG10	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-69	SDG10	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-75	SDG10	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-88	SDG10	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-90	SDG10	1	null	null
Qhalshs01883894	Economic Policy: Theory and Practice. Second edition Comprehensive and systematic approach to economic policy - Covers key issues: fiscal deficits, unconventional monetary policies, global imbalances, growth strategies, tax reform design, inequality in both breadth and depth - Provides insight into both real-world dilemmas and analytical tools to evaluate possible policies - Written by leading economists with policy experience  	L-93	SDG10	1	null	null
